{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple, Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "plt.style.use(snakemake.params.style)\n",
    "sns.set_palette(snakemake.params.palette)\n",
    "FIGSIZE = snakemake.params.figsize\n",
    "DPI = snakemake.params.dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(\n",
    "    data: pd.DataFrame, \n",
    "    x: str, \n",
    "    y: str, \n",
    "    title: str,\n",
    "    xtitle: Optional[str] = None,\n",
    "    ytitle: Optional[str] = None,\n",
    "    hue: Optional[str] = None, \n",
    "    ylim: Optional[Tuple[int, int]] = None\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE, dpi=DPI)\n",
    "    sns.boxenplot(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        hue=hue, \n",
    "        data=data, \n",
    "    )\n",
    "    \n",
    "    if ylim:\n",
    "        ax.set_ylim(ylim)\n",
    "        \n",
    "    ax.set_title(title)\n",
    "    \n",
    "    if xtitle:\n",
    "        ax.set_xlabel(xtitle)\n",
    "        \n",
    "    if ytitle:\n",
    "        ax.set_ylabel(ytitle)\n",
    "        \n",
    "    ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    ax.grid(b=True, which='major', linewidth=0.75, alpha=1.0)\n",
    "    ax.grid(b=True, which='minor', linewidth=0.5, alpha=0.5)\n",
    "        \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read BLAST identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_identity_files = snakemake.input.read_identity_csvs\n",
    "print(f\"{len(read_identity_files)} CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for csvfile in map(Path, read_identity_files):\n",
    "    df = pd.read_csv(csvfile)\n",
    "    sample, model = csvfile.name.split(\".\")[:2]\n",
    "    df[\"sample\"] = sample\n",
    "    df[\"model\"] = model\n",
    "    frames.append(df)\n",
    "data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the [BLAST identity][blast] for each read. Each sample has been grouped together into one violin plot per basecalling model. To get the BLAST identity, we basecalled the reads with the respective model and mapped those basecalls to the \"truth\" assembly. To calculate the BLAST identity for each mapping, we take the number of matching bases divided by the length of the alignment. For more information, refer to [this][pafpy-blast] implementation.  \n",
    "\n",
    "The Y-axis of the plot has been \"zoomed in\" to get a better sense of how the models compare.\n",
    "\n",
    "[blast]: https://lh3.github.io/2018/11/25/on-the-definition-of-sequence-identity#blast-identity\n",
    "[pafpy-blast]: https://pafpy.xyz/pafrecord.html#pafpy.pafrecord.PafRecord.blast_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Read-level accuracy\"\n",
    "xtitle = \"Basecalling model\"\n",
    "ytitle = \"BLAST identity\"\n",
    "ylim = (0.7, 1.0)\n",
    "x = \"model\"\n",
    "y = \"identity\"\n",
    "fig, ax = draw(data, x=x, y=y, ylim=ylim, title=title, xtitle=xtitle, ytitle=ytitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(snakemake.output.read_identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(x)[y].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative read length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define relative read length as the length of the *aligned* part of the read, divided by the total length of the read. The purpose of this metric is to see whether there is a bias towards insertions (greater than 1.0) or deletions (less than 1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Relative read length\"\n",
    "xtitle = \"Basecalling model\"\n",
    "ytitle = \"Relative length\"\n",
    "ylim = (0.85, 1.1)\n",
    "fig, ax = draw(data, x=\"model\", y=\"relative_len\", ylim=ylim, title=title, xtitle=xtitle, ytitle=ytitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(snakemake.output.read_relative_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(x)[y].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read length against read identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = snakemake.params.subsample\n",
    "sub_df = data.iloc[random.sample(range(len(data)), N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"read_len\"\n",
    "xtitle = \"Read length (bp)\"\n",
    "y = \"identity\"\n",
    "ytitle = \"BLAST identity\"\n",
    "title = \"Read length against identity\"\n",
    "\n",
    "log_ticks = [1, 100, 500, 1e3, 2e3, 3e3, 5e3, 1e4]\n",
    "xlim = (0, log_ticks[-1])\n",
    "ylim = (0.7, 1.0)\n",
    "\n",
    "jplot = sns.jointplot(\n",
    "    data=sub_df,\n",
    "    x=x, \n",
    "    y=y, \n",
    "    hue=\"model\",\n",
    "    kind=\"hist\",\n",
    "    alpha=0.8, \n",
    "    height=FIGSIZE[0],\n",
    ")\n",
    "_ = jplot.ax_joint.set(xticks=log_ticks, xlim=xlim, ylabel=ytitle, xlabel=xtitle, ylim=ylim)\n",
    "_ = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jplot.savefig(snakemake.output.read_identity_vs_len, dpi=DPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consensus accuracy\n",
    "Here we show consensus accuracy in a similar manner to read identity. Each \"read\" in this context is a result of chopping the [`rebaler`](https://github.com/rrwick/Rebaler) assembly of the reads up into 10Kbps \"chunks\" to simulate reads, and then mapping those chunks back to the original assembly using `minimap2` (and the `-x asm5` preset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_identity_files = snakemake.input.consensus_identity_csvs\n",
    "print(f\"{len(consensus_identity_files)} CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for csvfile in map(Path, consensus_identity_files):\n",
    "    df = pd.read_csv(csvfile)\n",
    "    sample, model = csvfile.name.split(\".\")[:2]\n",
    "    df[\"sample\"] = sample\n",
    "    df[\"model\"] = model\n",
    "    df[\"type\"] = \"consensus\"\n",
    "    frames.append(df)\n",
    "\n",
    "data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Consensus-level accuracy\"\n",
    "xtitle = \"Basecalling model\"\n",
    "ytitle = \"BLAST identity\"\n",
    "ylim = (0.996, 1.001)\n",
    "x = \"model\"\n",
    "y = \"identity\"\n",
    "fig, ax = draw(data, x=x, y=y, ylim=ylim, title=title, xtitle=xtitle, ytitle=ytitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(snakemake.output.consensus_identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(x)[y].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative \"read\" length for consensus chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Relative consensus length\"\n",
    "xtitle = \"Basecalling model\"\n",
    "ytitle = \"Relative length\"\n",
    "ylim = (0.997, 1.002)\n",
    "fig, ax = draw(data, x=\"model\", y=\"relative_len\", ylim=ylim, title=title, xtitle=xtitle, ytitle=ytitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(snakemake.output.consensus_relative_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(x)[y].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consensus error types\n",
    "Here we classify the types of errors that occur in the assemblies and look at how these errors compare across models. The errors are per-assembly, so the confidence intervals represent to variation in error types between samples/assemblies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_files = snakemake.input.asm_error_tsvs\n",
    "print(f\"{len(error_files)} TSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for csvfile in map(Path, error_files):\n",
    "    df = pd.read_csv(csvfile, sep=\"\\t\")\n",
    "    sample, model = csvfile.name.split(\".\")[:2]\n",
    "    df[\"sample\"] = sample\n",
    "    df[\"model\"] = model\n",
    "    df[\"type\"] = \"consensus\"\n",
    "    frames.append(df)\n",
    "\n",
    "id_vars = [\"sample\", \"model\", \"type\", \"assembly\"]\n",
    "value_vars = [\"dcm\", \"homo_del\", \"homo_ins\", \"other_del\", \"other_ins\", \"sub\"]\n",
    "data = pd.concat(frames).melt(id_vars=id_vars, value_vars=value_vars, var_name=\"error_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"error_type\"\n",
    "y = \"value\"\n",
    "hue = \"model\"\n",
    "kind = \"bar\"\n",
    "plot = sns.catplot(\n",
    "    data=data, \n",
    "    x=x, \n",
    "    y=y, \n",
    "    hue=hue, \n",
    "    kind=kind, \n",
    "    height=8, \n",
    "    aspect=1.5, \n",
    "    errwidth=1.5, \n",
    "    capsize=0.1\n",
    ")\n",
    "plot.set_xlabels(\"Error type\")\n",
    "plot.set_ylabels(\"Consensus error rate (%)\")\n",
    "plot.set(title=\"Consensus errors per model\")\n",
    "plot.ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "plot.ax.grid(b=True, which='major', linewidth=0.75)\n",
    "plot.ax.grid(b=True, which='minor', linewidth=0.5, alpha=0.5)\n",
    "plot.fig.set_dpi(DPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.fig.savefig(snakemake.output.error_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
