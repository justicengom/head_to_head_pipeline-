{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from typing import Tuple, Set\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import rgb2hex\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap(\"tab20\", 20)\n",
    "PALETTE = [rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
    "ggplot_cm = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "DELIM = \",\"\n",
    "PAIR_IDX = (\"sample1\", \"sample2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetrixMatrixError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def load_matrix(fpath, delim: str = DELIM, name: str = \"\") -> pd.Series:\n",
    "    matrix = []\n",
    "    with open(fpath) as instream:\n",
    "        header = next(instream).rstrip()\n",
    "        names = np.array(header.split(delim)[1:])\n",
    "        idx = np.argsort(names)\n",
    "        sorted_names = names[idx]\n",
    "        for row in map(str.rstrip, instream):\n",
    "            # sort row according to the name sorting\n",
    "            sorted_row = np.array(row.split(delim)[1:], dtype=int)[idx]\n",
    "            matrix.append(sorted_row)\n",
    "\n",
    "    sorted_matrix = np.array(matrix)[idx]\n",
    "    n_samples = len(sorted_names)\n",
    "    diagonal_is_zero = all(sorted_matrix[i, i] == 0 for i in range(n_samples))\n",
    "    if not diagonal_is_zero:\n",
    "        raise AsymmetrixMatrixError(\"Distance matrix diagonal is not all zero\")\n",
    "\n",
    "    matrix_is_symmetric = np.allclose(sorted_matrix, sorted_matrix.T)\n",
    "    if not matrix_is_symmetric:\n",
    "        raise AsymmetrixMatrixError(\"Distance matrix is not symmetric\")\n",
    "\n",
    "    mx = pd.DataFrame(sorted_matrix, columns=sorted_names, index=sorted_names)\n",
    "    # remove the lower triangle of the matrix and the middle diagonal\n",
    "    mx = mx.where(np.triu(np.ones(mx.shape), k=1).astype(bool))\n",
    "    mx = mx.stack().rename(name).astype(int)\n",
    "    mx = mx.rename_axis(PAIR_IDX)\n",
    "\n",
    "    return mx\n",
    "\n",
    "\n",
    "def matrix_to_graph(\n",
    "    mx: pd.Series, threshold: int, include_singletons: bool = False\n",
    ") -> nx.Graph:\n",
    "    edges = [(s1, s2, dist) for (s1, s2), dist in mx.iteritems() if dist <= threshold]\n",
    "    graph = nx.Graph()\n",
    "    graph.add_weighted_edges_from(edges)\n",
    "    if include_singletons:\n",
    "        samples = set()\n",
    "        for u in chain.from_iterable(mx.index):\n",
    "            if u not in samples:\n",
    "                graph.add_node(u)\n",
    "                samples.add(u)\n",
    "            if u not in samples:\n",
    "                graph.add_node(v)\n",
    "                samples.add(v)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def connected_components(G: nx.Graph, node: str) -> Set[str]:\n",
    "    if node not in G:\n",
    "        return set()\n",
    "    return nx.node_connected_component(G, node)\n",
    "\n",
    "\n",
    "def clustered_together(u: str, v: str, G: nx.Graph) -> bool:\n",
    "    ucc = connected_components(G, u)\n",
    "    if not ucc:\n",
    "        return False\n",
    "\n",
    "    vcc = connected_components(G, v)\n",
    "    if not vcc:\n",
    "        return False\n",
    "\n",
    "    return ucc == vcc\n",
    "\n",
    "\n",
    "def tversky_index(\n",
    "    A: Set[str], B: Set[str], alpha: float = 1.0, beta: float = 1.0\n",
    ") -> float:\n",
    "    \"\"\"If we set alpha and beta to 1 then we get the Jaccard Index.\n",
    "    If we set alpha to 1 and beta to 0 we get something like recall.\n",
    "    If we set alpha to 0 and beta to 1 we get something like precision.\n",
    "    \"\"\"\n",
    "    size_of_intersection = len(A & B)\n",
    "    A_weight = alpha * len(A - B)\n",
    "    B_weight = beta * len(B - A)\n",
    "    denominator = size_of_intersection + A_weight + B_weight\n",
    "\n",
    "    try:\n",
    "        return size_of_intersection / denominator\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def set_precision(A: Set[str], B: Set[str]) -> float:\n",
    "    return tversky_index(A, B, alpha=0, beta=1)\n",
    "\n",
    "\n",
    "def set_recall(A: Set[str], B: Set[str]) -> float:\n",
    "    return tversky_index(A, B, alpha=1, beta=0)\n",
    "\n",
    "\n",
    "def XCR(G: nx.Graph, H: nx.Graph) -> Tuple[float, int, int]:\n",
    "    expected_singletons = set(nx.isolates(G))\n",
    "    actual_singletons = set(nx.isolates(H))\n",
    "    denom = len(expected_singletons)\n",
    "    numer = len(expected_singletons - actual_singletons)\n",
    "    xcr = numer / denom\n",
    "    return xcr, numer, denom\n",
    "\n",
    "\n",
    "def SACP_AND_SACR(G: nx.Graph, H: nx.Graph) -> Tuple[float, float]:\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "    H.remove_nodes_from(list(nx.isolates(H)))\n",
    "\n",
    "    expected_clusters = list(nx.connected_components(G))\n",
    "    ppvs = []\n",
    "    tprs = []\n",
    "    for i, expected_cluster in enumerate(expected_clusters):\n",
    "        cluster_ppv = []\n",
    "        cluster_tpr = []\n",
    "        for node in expected_cluster:\n",
    "            actual_cluster = connected_components(H, node)\n",
    "            tpr = set_recall(expected_cluster, actual_cluster)\n",
    "            ppv = set_precision(expected_cluster, actual_cluster)\n",
    "            cluster_ppv.append(ppv)\n",
    "            cluster_tpr.append(tpr)\n",
    "        ppvs.extend(cluster_ppv)\n",
    "        tprs.extend(cluster_tpr)\n",
    "    return np.mean(ppvs), np.mean(tprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ont_thresholds = snakemake.params.thresholds\n",
    "thresholds = sorted(ont_thresholds.keys())\n",
    "clustering_metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in thresholds:\n",
    "\n",
    "    illumina_mtx = load_matrix(snakemake.input.illumina_dist, name=\"illumina\")\n",
    "    G_illumina = matrix_to_graph(illumina_mtx, threshold=t, include_singletons=True)\n",
    "    ont_mtx = load_matrix(snakemake.input.ont_dist, name=\"nanopore\")\n",
    "    G_ont = matrix_to_graph(\n",
    "        ont_mtx, threshold=ont_thresholds[t], include_singletons=True\n",
    "    )\n",
    "\n",
    "    assert len(G_illumina.nodes) == len(G_ont.nodes)\n",
    "\n",
    "    G = matrix_to_graph(illumina_mtx, threshold=t, include_singletons=True)\n",
    "    fig, axes = plt.subplots(\n",
    "        ncols=2,\n",
    "        figsize=snakemake.params.figsize,\n",
    "        dpi=300,\n",
    "    )\n",
    "\n",
    "    node_size = snakemake.params.node_size\n",
    "    edge_width = 3\n",
    "    lw = 1\n",
    "    font_size = 8\n",
    "    fw = \"normal\"\n",
    "    title_fontdict = dict(fontsize=9, fontweight=\"bold\")\n",
    "    align = \"horizontal\"\n",
    "    black = \"#2e3440\"\n",
    "    white = \"#eceff4\"\n",
    "    red = \"red\"\n",
    "    edge_colour = black\n",
    "    singleton_label = \"S\"\n",
    "    singleton_id = -1\n",
    "    singleton_node_colour = white\n",
    "    singleton_line_colour = red\n",
    "    singleton_lw = 3\n",
    "    singleton_shape = \"s\"  # square\n",
    "    singleton_hatch = \"///\"\n",
    "    singleton_ls = \"--\"\n",
    "    node_shape = \"o\"  # circle\n",
    "    colour_idx = -1\n",
    "    subset_key = \"cluster_id\"\n",
    "    node_colour_key = \"node_colour\"\n",
    "    label_key = \"label\"\n",
    "\n",
    "    node_colours = dict()\n",
    "    cluster_id = dict()\n",
    "    cluster_labels = dict()\n",
    "\n",
    "    for cluster in nx.connected_components(G):\n",
    "        if len(cluster) == 1:\n",
    "            colour = singleton_node_colour\n",
    "        else:\n",
    "            colour_idx += 1\n",
    "            colour = PALETTE[colour_idx]\n",
    "        for v in cluster:\n",
    "            node_colours[v] = colour\n",
    "            if colour == singleton_node_colour:\n",
    "                cluster_id[v] = singleton_id\n",
    "                cluster_labels[v] = singleton_label\n",
    "            else:\n",
    "                cluster_id[v] = colour_idx\n",
    "                cluster_labels[v] = str(colour_idx)\n",
    "\n",
    "    max_cluster_id = colour_idx + 1\n",
    "\n",
    "    for k, v in cluster_id.items():\n",
    "        if v == singleton_id:\n",
    "            cluster_id[k] = max_cluster_id\n",
    "\n",
    "    singleton_id = max_cluster_id\n",
    "\n",
    "    nx.set_node_attributes(G, node_colours, node_colour_key)\n",
    "    nx.set_node_attributes(G, cluster_id, subset_key)\n",
    "    nx.set_node_attributes(G, cluster_labels, label_key)\n",
    "\n",
    "    # remove singletons\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "    # add Illumina clustering plot\n",
    "    ax = axes.flatten()[0]\n",
    "\n",
    "    pos = nx.multipartite_layout(G, subset_key=subset_key, align=align)\n",
    "    cols = [d[node_colour_key] for v, d in G.nodes(data=True)]\n",
    "    labs = {v: d[label_key] for v, d in G.nodes(data=True)}\n",
    "\n",
    "    nx.draw(\n",
    "        G,\n",
    "        pos=pos,\n",
    "        ax=ax,\n",
    "        node_color=cols,\n",
    "        font_size=font_size,\n",
    "        labels=labs,\n",
    "        edgecolors=edge_colour,\n",
    "        font_weight=fw,\n",
    "        node_size=node_size,\n",
    "        width=edge_width,\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"Illumina | threshold={t}\", fontdict=title_fontdict)\n",
    "\n",
    "    M = ont_mtx\n",
    "    T = ont_thresholds\n",
    "    tool = \"bcftools\"\n",
    "    ax = axes.flatten()[1]\n",
    "    tool_t = T[t]\n",
    "    H = matrix_to_graph(M, threshold=tool_t, include_singletons=True)\n",
    "    xcr_data = XCR(G_illumina.copy(), H.copy())\n",
    "\n",
    "    nx.set_node_attributes(H, node_colours, node_colour_key)\n",
    "    nx.set_node_attributes(H, cluster_id, subset_key)\n",
    "    nx.set_node_attributes(H, cluster_labels, label_key)\n",
    "\n",
    "    # remove singletons that were also singletons in Illumina\n",
    "    for v in list(nx.isolates(H)):\n",
    "        if node_colours[v] == singleton_node_colour:  # is also singleton in Illumina\n",
    "            H.remove_node(v)\n",
    "        else:  # is not singleton in Illumina\n",
    "            H.nodes[v][subset_key] = singleton_id\n",
    "\n",
    "    # give nodes that were singleton on Illumina, but now clustered\n",
    "    # in Nanopore the cluster ID of their nanopore cluster\n",
    "    clusters = nx.connected_components(H)\n",
    "    for c in clusters:\n",
    "        ids = {H.nodes[v][subset_key] for v in c}\n",
    "        if len(ids) == 1:\n",
    "            continue\n",
    "        sorted_ids = sorted(ids)\n",
    "        new_id = sorted_ids[0]\n",
    "\n",
    "        for v in c:\n",
    "            H.nodes[v][subset_key] = new_id\n",
    "\n",
    "    # if there are more than n nodes in the singletons line, split over more lines\n",
    "    n = 10\n",
    "    count = 0\n",
    "    new_id = singleton_id + 1\n",
    "    to_change = []\n",
    "    for v, d in H.nodes(data=True):\n",
    "        if d[subset_key] == singleton_id:\n",
    "            count += 1\n",
    "            if count >= n:\n",
    "                to_change.append(v)\n",
    "\n",
    "    for v in to_change:\n",
    "        H.nodes[v][subset_key] = new_id\n",
    "        for u in connected_components(H, v):\n",
    "            H.nodes[u][subset_key] = new_id\n",
    "\n",
    "    pos = nx.multipartite_layout(H, subset_key=subset_key, align=align)\n",
    "    labs = {v: d[label_key] for v, d in H.nodes(data=True)}\n",
    "    sacp, sacr = SACP_AND_SACR(\n",
    "        matrix_to_graph(illumina_mtx, threshold=t, include_singletons=False),\n",
    "        matrix_to_graph(M, threshold=tool_t, include_singletons=False),\n",
    "    )\n",
    "\n",
    "    for shape in [singleton_shape, node_shape]:\n",
    "        if shape == singleton_shape:\n",
    "            vs = [k for k, v in labs.items() if v == singleton_label]\n",
    "        else:\n",
    "            vs = [k for k, v in labs.items() if v != singleton_label]\n",
    "        ps = {v: pos[v] for v in vs}\n",
    "        cols = [H.nodes[v][node_colour_key] for v in vs]\n",
    "\n",
    "        node_ax = nx.draw_networkx_nodes(\n",
    "            H,\n",
    "            pos=ps,\n",
    "            nodelist=vs,\n",
    "            node_color=cols,\n",
    "            node_shape=shape,\n",
    "            edgecolors=edge_colour,\n",
    "            ax=ax,\n",
    "            node_size=node_size,\n",
    "        )\n",
    "        if shape == singleton_shape:\n",
    "            node_ax.set_hatch(singleton_hatch)\n",
    "            node_ax.set_edgecolor(singleton_line_colour)\n",
    "            node_ax.set_linestyle(singleton_ls)\n",
    "\n",
    "    nx.draw_networkx_edges(H, pos, ax=ax, edge_color=edge_colour, width=edge_width)\n",
    "    nx.draw_networkx_labels(\n",
    "        H, pos, labels=labs, ax=ax, font_size=font_size, font_weight=fw\n",
    "    )\n",
    "\n",
    "    fs = 7.5\n",
    "\n",
    "    c = mpatches.Circle((1, 1), 0.0001, color=white)\n",
    "    metrics = [\n",
    "        f\"SACR={sacr:.3f}\",\n",
    "        f\"SACP={sacp:.3f}\",\n",
    "        f\"XCR={xcr_data[0]:.3f} ({xcr_data[1]}/{xcr_data[2]})\",\n",
    "    ]\n",
    "\n",
    "    clustering_metrics.append([t, tool_t, sacr, sacp, *xcr_data])\n",
    "\n",
    "    location = dict(loc=\"upper right\")  # bbox_to_anchor=(0.99, 0.5))\n",
    "\n",
    "    ax.legend(\n",
    "        [c] * len(metrics),\n",
    "        metrics,\n",
    "        facecolor=white,\n",
    "        handlelength=0.1,\n",
    "        handletextpad=0.1,\n",
    "        fontsize=fs,\n",
    "        framealpha=0.5,\n",
    "        edgecolor=black,\n",
    "        frameon=True,\n",
    "        **location,\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{tool} | threshold={tool_t}\", fontdict=title_fontdict)\n",
    "\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        fc = ax.get_facecolor()\n",
    "        if i % 2:\n",
    "            ax.spines[\"left\"].set_color(\"black\")\n",
    "        else:\n",
    "            ax.spines[\"left\"].set_color(fc)\n",
    "        ax.spines[\"top\"].set_color(fc)\n",
    "        ax.spines[\"right\"].set_color(fc)\n",
    "        ax.spines[\"bottom\"].set_color(fc)\n",
    "\n",
    "    plt.tight_layout(h_pad=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    clustering_metrics,\n",
    "    columns=[\n",
    "        \"illumina_threshold\",\n",
    "        \"nanopore_threshold\",\n",
    "        \"SACR\",\n",
    "        \"SACP\",\n",
    "        \"XCR\",\n",
    "        \"clustered_singletons\",\n",
    "        \"expected_singletons\",\n",
    "    ],\n",
    ")\n",
    "df.to_csv(snakemake.output[0], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
