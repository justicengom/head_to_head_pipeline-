import os
from pathlib import Path
from typing import Dict, Union, List

import pandas as pd
from snakemake.utils import min_version

min_version("5.14.0")

GB = 1_024
PathLike = Union[str, Path, os.PathLike]


# ======================================================
# Config files
# ======================================================
configfile: "config.yaml"


# only load samples that passed QC and are not excluded
inclusion_expr = "failed_qc == 0 and excluded == 0"
samplesheet = pd.read_csv(config["samplesheet"]).query(inclusion_expr)
containers: Dict[str, PathLike] = config["containers"]
envs: Dict[str, PathLike] = config["envs"]
scripts: Dict[str, PathLike] = config["scripts"]
rule_log_dir = Path("logs/stderr").resolve()
H37RV = config["h37rv"]
data_dir = Path(config["data_dir"]).resolve()
build_prg_dir = Path(config["build_prg_dir"])
qc_dir = Path(config["qc_dir"])
filters = config["filters"]
discover = config["discover"]
report_dir = Path("report").resolve()
compass_vcf_dir = Path(config["compass_vcf_dir"]).resolve()
asm_dir = Path(config["asm_dir"]).resolve()
assemblies: Dict[str, str] = config["assemblies"]
nanopore_dir = Path("nanopore").resolve()
concordance_dir = Path("concordance").resolve()
consensus_dir = Path("consensus").resolve()
distance_dir = Path("distance").resolve()
truth_eval_dir = Path("truth_eval").resolve()
discover_dir = nanopore_dir / "discover"
genotype_dir = nanopore_dir / "genotype"
compare_dir = nanopore_dir / "compare"
filter_dir = nanopore_dir / "filtered"
baseline_variant_dir = Path(config["baseline_variant_dir"]).resolve()
# ======================================================
# Global functions and variables
# ======================================================
K: int = config["pandora_k"]
W: int = config["pandora_w"]
SITES = samplesheet["site"]
SAMPLES = samplesheet["sample"]
VARIFIER_JSONS_ALL = set()
VARIFIER_JSONS_SNP = set()
VARIFIER_JSONS_INDELS = set()
prg_names: List[str] = config["prg_names"]

output_files = set()
for idx, row in samplesheet.iterrows():
    site = row["site"]
    sample = row["sample"]

    for prg_name in prg_names:
        output_files.add(
            concordance_dir / f"{prg_name}/{site}/{sample}.concordance.json"
        )
        output_files.add(distance_dir / f"{prg_name}.heatmap.html")
        output_files.add(
            compare_dir / f"{prg_name}/pandora/pandora_multisample_genotyped.vcf"
        )

        if row["pacbio"] == 1:
            pandora_truth_summary = (
                truth_eval_dir / f"all_variants/{prg_name}/{sample}/summary_stats.json"
            )
            pandora_truth_snps_summary = (
                truth_eval_dir / f"snps/{prg_name}/{sample}/summary_stats.json"
            )
            pandora_truth_indels_summary = (
                truth_eval_dir / f"indels/{prg_name}/{sample}/summary_stats.json"
            )
            # compass_truth_summary = baseline_variant_dir / f"truth_eval/{sample}/compass/summary_stats.json"
            VARIFIER_JSONS_ALL.add(pandora_truth_summary)
            VARIFIER_JSONS_SNP.add(pandora_truth_snps_summary)
            VARIFIER_JSONS_INDELS.add(pandora_truth_indels_summary)
# VARIFIER_JSONS.add(compass_truth_summary)

output_files.add(truth_eval_dir / "all_variants/truth_all_eval.recall.png")
output_files.add(truth_eval_dir / "all_variants/truth_all_eval.precision.png")
output_files.add(truth_eval_dir / "snps/truth_snps_eval.recall.png")
output_files.add(truth_eval_dir / "snps/truth_snps_eval.precision.png")
output_files.update(VARIFIER_JSONS_INDELS)


# ======================================================
# Sub Workflows
# ======================================================
subworkflow build_prg:
    workdir: build_prg_dir
    snakefile: build_prg_dir / "Snakefile"
    configfile: build_prg_dir / "config.yaml"


subworkflow qc:
    workdir: qc_dir
    snakefile: qc_dir / "Snakefile"
    configfile: qc_dir / "config.yaml"


# ======================================================
# Rules
# ======================================================
localrules:
    all,


rule all:
    input:
        output_files,


rule discover_denovo_variants:
    input:
        prg=build_prg("prgs/{prg_name}/{prg_name}.prg"),
        prg_index=build_prg(f"prgs/{{prg_name}}/{{prg_name}}.prg.k{K}.w{W}.idx"),
        reads=qc("subsampled/{site}/nanopore/{sample}/{sample}.subsampled.fastq.gz"),
    output:
        denovo_dir=directory(discover_dir / "{prg_name}/{site}/{sample}/denovo_paths"),
        consensus=discover_dir / "{prg_name}/{site}/{sample}/pandora.consensus.fq.gz",
    threads: 8
    resources:
        mem_mb=lambda wildcards, attempt: int(4 * GB) * attempt,
    container:
        containers["pandora"]
    log:
        rule_log_dir / "discover_denovo_variants/{prg_name}/{site}/{sample}.log",
    params:
        outdir=lambda wildcards, output: Path(output.denovo_dir).parent,
        prg=lambda wildcards, input: Path(input.prg).resolve(),
        reads=lambda wildcards, input: Path(input.reads).resolve(),
        options=" ".join(
            [
                f"-k {K}",
                f"-w {W}",
                f"-e {config['pandora_e']}",
                f"-g {config['genome_size']}",
                "-v",
                "--mapped-reads",
                f"--min-dbg-dp {discover['min_dbg_abundance']}",
                f"-d {discover['merge_dist']}",
                f"--discover-k {discover['kmer_size']}",
                f"-L {discover['max_candidate_len']}",
                f'{"--clean-dbg" if discover["clean"] else ""}',
                f"--max-ins {discover['max_insertion']}",
                f"-N {discover['max_nb_paths']}",
            ]
        ),
    shell:
        """
        LOG=$(realpath {log})
        cd {params.outdir} || exit 1
        rm -rf ./*
        pandora discover {params.options} -t {threads} -o "$PWD" {params.prg} {params.reads} > "$LOG" 2>&1
        """


rule update_msas_for_single_sample:
    input:
        denovo_paths=rules.discover_denovo_variants.output.denovo_dir,
        msa_dir=build_prg("prgs/{prg_name}/multiple_sequence_alignments"),
    output:
        updated_msas=directory(
            discover_dir / "{prg_name}/{site}/{sample}/updated_msas"
        ),
    threads: 16
    resources:
        mem_mb=lambda wildcards, attempt: int(16 * GB) * attempt,
    container:
        containers["conda"]
    conda:
        envs["update_msas"]
    log:
        rule_log_dir / "update_msas_for_single_sample/{prg_name}/{site}/{sample}.log",
    params:
        script=scripts["update_msas"],
        options="",
    shell:
        """
        python {params.script} {params.options} -o {output.updated_msas} \
            -j {threads} -M {input.msa_dir} {input.denovo_paths} 2> {log}
        """


rule make_single_sample_local_prgs:
    input:
        msa_dir=rules.update_msas_for_single_sample.output.updated_msas,
    output:
        local_prg_dir=directory(
            discover_dir / "{prg_name}/{site}/{sample}/local_prgs"
        ),
    threads: 16
    resources:
        mem_mb=lambda wildcards, attempt: int(4 * GB) * attempt,
    container:
        containers["make_prg"]
    params:
        extras="--no-ignore --hidden --show-errors",
        extension="fa",
        pattern=".",
        script=scripts["make_prg"],
        nesting_lvl=config["nesting_level"],
        match_len=config["match_length"],
    log:
        rule_log_dir / "make_single_sample_local_prgs/{prg_name}/{site}/{sample}.log",
    shell:
        """
        mkdir -p {output.local_prg_dir} 2> {log}
        fd {params.extras} \
            --extension {params.extension} \
            --threads {threads} \
            --exec sh {params.script} '{{}}' \
                {output.local_prg_dir}/'{{/.}}' \
                {params.nesting_lvl} \
                {params.match_len} \
                {log} \; \
            {params.pattern} {input.msa_dir} 2>> {log}
        """


rule combine_single_sample_local_prgs:
    input:
        local_prg_dir=rules.make_single_sample_local_prgs.output.local_prg_dir,
    output:
        prg=discover_dir / "{prg_name}/{site}/{sample}/{prg_name}.{sample}.prg",
    threads: 1
    resources:
        mem_mb=int(0.5 * GB),
    params:
        extras="--no-ignore --hidden",
        extension="prg",
        pattern=".",
    container:
        containers["conda"]
    conda:
        envs["fd"]
    log:
        rule_log_dir / "combine_single_sample_local_prgs/{prg_name}/{site}/{sample}.log",
    shell:
        """
        fd {params.extras} \
            --extension {params.extension} \
            --exec-batch awk 1 \; \
            {params.pattern} {input.local_prg_dir} > {output.prg} 2> {log}
        """


rule index_single_sample_updated_prg:
    input:
        prg=rules.combine_single_sample_local_prgs.output.prg,
    output:
        index=(
            discover_dir
            / f"{{prg_name}}/{{site}}/{{sample}}/{{prg_name}}.{{sample}}.prg.k{K}.w{W}.idx"
        ),
        kmer_prgs=directory(discover_dir / "{prg_name}/{site}/{sample}/kmer_prgs"),
    threads: 16
    resources:
        mem_mb=lambda wildcards, attempt: int(8 * GB) * attempt,
    params:
        K=K,
        W=W,
    log:
        rule_log_dir / "index_single_sample_updated_prg/{prg_name}/{site}/{sample}.log",
    container:
        containers["pandora"]
    shell:
        """
        pandora index -k {params.K} -w {params.W} -t {threads} {input.prg} > {log} 2>&1
        """


rule single_sample_genotype:
    input:
        prg=rules.combine_single_sample_local_prgs.output.prg,
        prg_index=rules.index_single_sample_updated_prg.output.index,
        reads=rules.discover_denovo_variants.input.reads,
        vcf_refs=build_prg("prgs/reference_loci/loci_reference.fa"),
    output:
        vcf=genotype_dir / f"{{prg_name}}/{{site}}/{{sample}}/pandora_genotyped.vcf",
    threads: 8
    resources:
        mem_mb=lambda wildcards, attempt: int(4 * GB) * attempt,
    container:
        containers["pandora"]
    log:
        rule_log_dir / "single_sample_genotype/{prg_name}/{site}/{sample}.log",
    params:
        outdir=lambda wildcards, output: Path(output.vcf).parent,
        max_covg=1_000,  # i.e. disable subsampling
        prg=lambda wildcards, input: Path(input.prg).resolve(),
        reads=lambda wildcards, input: Path(input.reads).resolve(),
        vcf_refs=lambda wildcards, input: Path(input.vcf_refs).resolve(),
        options=" ".join(
            [
                f"--genotype",
                f"-k {K}",
                f"-w {W}",
                f"-e {config['pandora_e']}",
                f"-E {config['pandora_E']}",
                f"-g {config['genome_size']}",
                "--kg",
                "--loci-vcf",
                "--mapped-reads",
            ]
        ),
    shell:
        """
        LOG=$(realpath {log})
        cd {params.outdir} || exit 1
        rm -rf ./*
        pandora map {params.options} -t {threads} -o "$PWD" --vcf-refs {params.vcf_refs} \
            {params.prg} {params.reads}  > "$LOG" 2>&1
        """


rule normalise_single_sample_vcf:
    input:
        vcf=rules.single_sample_genotype.output.vcf,
        loci_info=build_prg("prgs/reference_loci/loci-info.csv"),
        ref=H37RV["genome"],
    output:
        vcf=genotype_dir / "{prg_name}/{site}/{sample}/{sample}.normalised.bcf",
    log:
        rule_log_dir / "normalise_single_sample_vcf_positions/{prg_name}/{site}/{sample}.log",
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: int(2 * GB) * attempt,
    params:
        norm_pos_opts="-v",
        script=scripts["normalise_pos"],
        norm_opts="-c e -O b",
        view_opts="-a",  # trim alts
    container:
        containers["conda"]
    conda:
        envs["normalise_pos"]
    shell:
        """
        ( python {params.script} -i {input.vcf} -l {input.loci_info} -r {input.ref} {params.norm_pos_opts} \
        | bcftools view {params.view_opts} \
        | bcftools sort \
        | bcftools norm {params.norm_opts} -f {input.ref} -o {output.vcf}) 2> {log}
        """


rule filter_single_sample_vcf:
    input:
        vcf=rules.normalise_single_sample_vcf.output.vcf,
    output:
        vcf=filter_dir / "{prg_name}/{site}/{sample}.filtered.bcf",
    threads: 1
    resources:
        mem_mb=int(0.5 * GB),
    params:
        options=" ".join(
            [
                "--verbose",
                "--overwrite",
                f"-d {filters['min_covg']}",
                f"-D {filters['max_covg']}",
                f"-s {filters['min_strand_bias']}",
                f"-g {filters['min_gt_conf']}",
                f"-G {filters['max_gaps']}",
                f"-I {filters['max_indel']}",
            ]
        ),
        script=scripts["filter"],
    log:
        rule_log_dir / "filter_single_sample_vcf/{prg_name}/{site}/{sample}.log",
    container:
        containers["conda"]
    conda:
        envs["filter"]
    shell:
        """
        python {params.script} {params.options} \
            -i {input.vcf} \
            -o {output.vcf} 2> {log}
        """


def infer_assembly_path(wildcards):
    asm = assemblies[wildcards.sample]
    return f"{asm_dir}/{wildcards.sample}/{asm}/pacbio/decontam.assembly.{asm}.pacbio.fasta"


def infer_assembly_mask_path(wildcards):
    asm = assemblies[wildcards.sample]
    return f"{asm_dir}/{wildcards.sample}/{asm}/pacbio/assessment/{wildcards.sample}.{asm}.accuracy.pacbio.bed"


rule evaluate_all_variants_single_sample:
    input:
        truth_asm=infer_assembly_path,
        vcf_ref=H37RV["genome"],
        vcf_to_eval=filter_dir / "{prg_name}/madagascar/{sample}.filtered.bcf",
        ref_mask=H37RV["mask"],
        truth_mask=infer_assembly_mask_path,
    output:
        summary=report(
            truth_eval_dir / "all_variants/{prg_name}/{sample}/summary_stats.json",
            category="Truth Evaluation - All Variants",
            subcategory="Raw data",
            caption=report_dir / "varifier.rst",
        ),
    threads: 4
    resources:
        mem_mb=lambda wildcards, attempt: int(10 * GB) * attempt,
    params:
        options="--force --filter_pass PASS,.",
        flank_length=100,
        outdir=lambda wildcards, output: Path(output.summary).parent,
    log:
        rule_log_dir / "evaluate_all_variants_single_sample/{prg_name}/{sample}.log",
    container:
        containers["conda"]
    conda:
        envs["varifier"]
    shell:
        """
        (bcftools view -O v {input.vcf_to_eval} \
        | varifier --debug vcf_eval {params.options} \
            --flank_length {params.flank_length} \
            --ref_mask {input.ref_mask} \
            --truth_mask {input.truth_mask} \
            {input.truth_asm} \
            {input.vcf_ref} \
            - \
            {params.outdir}) 2> {log}
        """


rule plot_evaluation_all_variants_single_sample:
    input:
        json_files=VARIFIER_JSONS_ALL,
    output:
        recall_plot=report(
            truth_eval_dir / "all_variants/truth_all_eval.recall.png",
            category="Truth Evaluation - All Variants",
            subcategory="Recall",
            caption=report_dir / "truth_all_eval.rst",
        ),
        precision_plot=report(
            truth_eval_dir / "all_variants/truth_all_eval.precision.png",
            category="Truth Evaluation - All Variants",
            subcategory="Precision",
            caption=report_dir / "truth_all_eval.rst",
        ),
    threads: 1
    resources:
        mem_mb=int(GB * 0.5),
    container:
        containers["conda"]
    conda:
        envs["plot_truth_eval"]
    params:
        recall_key="Recall_edit_dist",
        precision_key="Precision_edit_dist",
        dpi=300,
        figsize=(13, 8),
    log:
        rule_log_dir / "plot_evaluation_all_variants_single_sample.log",
    script:
        scripts["plot_truth_eval"]


rule extract_snps:
    input:
        vcf=rules.filter_single_sample_vcf.output.vcf,
    output:
        vcf=filter_dir / "{prg_name}/{site}/{sample}.snps.filtered.bcf",
    threads: 1
    resources:
        mem_mb=int(0.5 * GB),
    container:
        containers["conda"]
    conda:
        envs["extract_snps"]
    params:
        script=scripts["extract_snps"],
        extra="--keep-mnps -v",
    log:
        rule_log_dir / "extract_snps/{prg_name}/{site}/{sample}.log",
    shell:
        "python {params.script} {params.extra} -i {input.vcf} -o {output.vcf} 2> {log}"


rule extract_indels:
    input:
        vcf=rules.filter_single_sample_vcf.output.vcf,
    output:
        vcf=filter_dir / "{prg_name}/{site}/{sample}.indels.filtered.bcf",
    threads: 1
    resources:
        mem_mb=int(0.5 * GB),
    container:
        containers["bcftools"]
    params:
        extra="-O b -v indels",
    log:
        rule_log_dir / "extract_indels/{prg_name}/{site}/{sample}.log",
    shell:
        "bcftools view {params.extra} --threads {threads} -o {output.vcf} {input.vcf} 2> {log}"


rule evaluate_snps_single_sample:
    input:
        truth_asm=infer_assembly_path,
        vcf_ref=H37RV["genome"],
        vcf_to_eval=filter_dir / "{prg_name}/madagascar/{sample}.snps.filtered.bcf",
        ref_mask=H37RV["mask"],
        truth_mask=infer_assembly_mask_path,
    output:
        summary=report(
            truth_eval_dir / "snps/{prg_name}/{sample}/summary_stats.json",
            category="Truth Evaluation - SNPs",
            subcategory="Raw data",
            caption=report_dir / "varifier.rst",
        ),
    threads: 4
    resources:
        mem_mb=lambda wildcards, attempt: int(10 * GB) * attempt,
    params:
        options="--force --filter_pass PASS,.",
        flank_length=100,
        outdir=lambda wildcards, output: Path(output.summary).parent,
    log:
        rule_log_dir / "evaluate_snps_single_sample/{prg_name}/{sample}.log",
    container:
        containers["conda"]
    conda:
        envs["varifier"]
    shell:
        """
        (bcftools view -O v {input.vcf_to_eval} \
        | varifier --debug vcf_eval {params.options} \
            --flank_length {params.flank_length} \
            --ref_mask {input.ref_mask} \
            --truth_mask {input.truth_mask} \
            {input.truth_asm} \
            {input.vcf_ref} \
            - \
            {params.outdir}) 2> {log}
        """


rule evaluate_indels_single_sample:
    input:
        truth_asm=infer_assembly_path,
        vcf_ref=H37RV["genome"],
        vcf_to_eval=filter_dir / "{prg_name}/madagascar/{sample}.indels.filtered.bcf",
        ref_mask=H37RV["mask"],
        truth_mask=infer_assembly_mask_path,
    output:
        summary=report(
            truth_eval_dir / "indels/{prg_name}/{sample}/summary_stats.json",
            category="Truth Evaluation - indels",
            subcategory="Raw data",
            caption=report_dir / "varifier.rst",
        ),
    threads: 4
    resources:
        mem_mb=lambda wildcards, attempt: int(10 * GB) * attempt,
    params:
        options="--force --filter_pass PASS,.",
        flank_length=100,
        outdir=lambda wildcards, output: Path(output.summary).parent,
    log:
        rule_log_dir / "evaluate_indels_single_sample/{prg_name}/{sample}.log",
    container:
        containers["conda"]
    conda:
        envs["varifier"]
    shell:
        """
        (bcftools view -O v {input.vcf_to_eval} \
        | varifier --debug vcf_eval {params.options} \
            --flank_length {params.flank_length} \
            --ref_mask {input.ref_mask} \
            --truth_mask {input.truth_mask} \
            {input.truth_asm} \
            {input.vcf_ref} \
            - \
            {params.outdir}) 2> {log}
        """


rule plot_evaluation_snps_single_sample:
    input:
        json_files=VARIFIER_JSONS_SNP,
    output:
        recall_plot=report(
            truth_eval_dir / "snps/truth_snps_eval.recall.png",
            category="Truth Evaluation - SNPs",
            subcategory="Recall",
            caption=report_dir / "truth_snps_eval.rst",
        ),
        precision_plot=report(
            truth_eval_dir / "snps/truth_snps_eval.precision.png",
            category="Truth Evaluation - SNPs",
            subcategory="Precision",
            caption=report_dir / "truth_snps_eval.rst",
        ),
    threads: 1
    resources:
        mem_mb=int(GB * 0.5),
    container:
        containers["conda"]
    conda:
        envs["plot_truth_eval"]
    params:
        recall_key="Recall_edit_dist",
        precision_key="Precision_edit_dist",
        dpi=300,
        figsize=(13, 8),
    log:
        rule_log_dir / "plot_evaluation_snps_single_sample.log",
    script:
        scripts["plot_truth_eval"]


rule generate_consensus:
    input:
        mask=H37RV["mask"],
        ref_fasta=H37RV["genome"],
        vcf=rules.extract_snps.output.vcf,
    output:
        fasta=consensus_dir / "{prg_name}/{site}/{sample}.consensus.fa",
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: int(GB) * attempt,
    container:
        containers["conda"]
    conda:
        envs["consensus"]
    params:
        options=" ".join(
            [
                "--verbose",
                "-I null -I filter -I mask",
                "--sample-id {sample}",
                "--het-default none",
            ]
        ),
        script=scripts["consensus"],
    log:
        rule_log_dir / "generate_consensus/{prg_name}/{site}/{sample}.log",
    shell:
        """
        python {params.script} {params.options} \
            -i {input.vcf} \
            -f {input.ref_fasta} \
            -m {input.mask} \
            -o {output.fasta} 2> {log}
        """


rule aggregate_consensus:
    input:
        fastas=expand(
            consensus_dir / "{{prg_name}}/{site}/{sample}.consensus.fa",
            zip,
            site=SITES,
            sample=SAMPLES,
        ),
    output:
        fasta=consensus_dir / "{prg_name}/pandora.{prg_name}.consensus.fa",
    threads: 1
    resources:
        mem_mb=int(GB),
    log:
        rule_log_dir / "aggregate_consensus/{prg_name}.log",
    shell:
        "awk 1 {input.fastas} > {output.fasta} 2> {log}"


rule snp_distance:
    input:
        fasta=rules.aggregate_consensus.output.fasta,
    output:
        matrix=report(
            distance_dir / "pandora.{prg_name}.matrix.csv",
            category="Distance",
            subcategory="Data",
            caption=report_dir / "distance.rst",
        ),
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: int(GB) * attempt,
    container:
        containers["snp-dists"]
    log:
        rule_log_dir / "snp_distance/{prg_name}.log",
    params:
        options="-c",
    shell:
        "snp-dists {params.options} {input.fasta} 2> {log} > {output.matrix}"


rule plot_distance_matrix:
    input:
        matrix=rules.snp_distance.output.matrix,
    output:
        plot=report(
            distance_dir / "{prg_name}.heatmap.html",
            category="Distance",
            subcategory="Plot",
            caption=report_dir / "plot_distance_matrix.rst",
        ),
    params:
        script=scripts["plot_distance_matrix"],
        options=" ".join(
            ["--delim ,", "--title 'Pandora {prg_name} PRG pairwise distance'",]
        ),
    threads: 1
    resources:
        mem_mb=int(GB),
    container:
        containers["conda"]
    conda:
        envs["plot_distance_matrix"]
    log:
        rule_log_dir / "plot_distance_matrix/{prg_name}.log",
    shell:
        "python {params.script} {params.options} -i {input.matrix} -o {output.plot} 2> {log}"


rule calculate_concordance:
    input:
        truth=compass_vcf_dir / "{sample}.compass.vcf.gz",
        query=rules.extract_snps.output.vcf,
        mask=H37RV["mask"],
    output:
        csv=concordance_dir / "{prg_name}/{site}/{sample}.concordance.csv",
        json=report(
            concordance_dir / "{prg_name}/{site}/{sample}.concordance.json",
            category="Concordance",
            subcategory="Raw Data",
            caption=f"{report_dir}/calculate_concordance.rst",
        ),
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: int(2 * GB) * attempt,
    params:
        options="--verbose --apply-filter",
        script=scripts["concordance"],
    log:
        rule_log_dir / "calculate_concordance/{prg_name}/{site}/{sample}.log",
    container:
        containers["conda"]
    conda:
        envs["concordance"]
    shell:
        """
        python {params.script} {params.options} \
            -a {input.truth} \
            -b {input.query} \
            -m {input.mask} \
            -c {output.csv} \
            -j {output.json} 2> {log}
        """


rule aggregate_denovo_paths:
    input:
        denovo_dirs=expand(
            discover_dir / "{{prg_name}}/{site}/{sample}/denovo_paths",
            zip,
            site=SITES,
            sample=SAMPLES,
        ),
    output:
        outdir=directory(compare_dir / "{prg_name}/denovo_paths/all"),
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: int(GB) * attempt,
    container:
        containers["conda"]
    log:
        rule_log_dir / "aggregate_denovo_paths/{prg_name}.log",
    script:
        scripts["aggregate_denovo_paths"]


rule deduplicate_denovo_paths:
    input:
        denovo_paths=rules.aggregate_denovo_paths.output.outdir,
    output:
        outdir=directory(compare_dir / "{prg_name}/denovo_paths/deduplicated"),
    threads: 16
    resources:
        mem_mb=lambda wildcards, attempt: int(8 * GB) * attempt,
    container:
        containers["conda"]
    conda:
        envs["deduplicate_fasta"]
    log:
        rule_log_dir / "deduplicate_denovo_paths/{prg_name}.log",
    params:
        script=scripts["deduplicate_fasta"],
    shell:
        """
        mkdir {output.outdir} 2> {log}
        fd -j {threads} \
          -e fa \
          -x bash {params.script} '{{}}' {output.outdir} \; \
          . {input.denovo_paths} 2>> {log}
        """


rule update_msas_for_multi_sample:
    input:
        denovo_paths=rules.deduplicate_denovo_paths.output.outdir,
        msa_dir=build_prg("prgs/{prg_name}/multiple_sequence_alignments"),
    output:
        updated_msas=directory(compare_dir / "{prg_name}/updated_msas"),
    threads: 32
    resources:
        mem_mb=lambda wildcards, attempt: int(32 * GB) * attempt,
    container:
        containers["conda"]
    conda:
        envs["update_msas"]
    log:
        rule_log_dir / "update_msas_for_multi_sample/{prg_name}.log",
    params:
        script=scripts["update_msas"],
        options="",
    shell:
        """
        python {params.script} {params.options} -o {output.updated_msas} \
            -j {threads} -M {input.msa_dir} {input.denovo_paths} 2> {log}
        """


rule make_multi_sample_local_prgs:
    input:
        msa_dir=rules.update_msas_for_multi_sample.output.updated_msas,
    output:
        local_prg_dir=directory(compare_dir / "{prg_name}/local_prgs"),
    threads: 16
    resources:
        mem_mb=lambda wildcards, attempt: int(4 * GB) * attempt,
    container:
        containers["make_prg"]
    params:
        extras="--no-ignore --hidden --show-errors",
        extension="fa",
        pattern=".",
        script=scripts["make_prg"],
        nesting_lvl=config["nesting_level"],
        match_len=config["match_length"],
    log:
        rule_log_dir / "make_multi_sample_local_prgs/{prg_name}.log",
    shell:
        """
        mkdir -p {output.local_prg_dir} 2> {log}
        fd {params.extras} \
            --extension {params.extension} \
            --threads {threads} \
            --exec sh {params.script} '{{}}' \
                {output.local_prg_dir}/'{{/.}}' \
                {params.nesting_lvl} \
                {params.match_len} \
                {log} \; \
            {params.pattern} {input.msa_dir} 2>> {log}
        """


rule combine_multi_sample_local_prgs:
    input:
        local_prg_dir=rules.make_multi_sample_local_prgs.output.local_prg_dir,
    output:
        prg=compare_dir / "{prg_name}/{prg_name}.prg",
    threads: 1
    resources:
        mem_mb=int(0.5 * GB),
    params:
        extras="--no-ignore --hidden",
        extension="prg",
        pattern=".",
    container:
        containers["conda"]
    conda:
        envs["fd"]
    log:
        rule_log_dir / "combine_multi_sample_local_prgs/{prg_name}.log",
    shell:
        """
        fd {params.extras} \
            --extension {params.extension} \
            --exec-batch awk 1 \; \
            {params.pattern} {input.local_prg_dir} > {output.prg} 2> {log}
        """


rule index_multi_sample_updated_prg:
    input:
        prg=rules.combine_multi_sample_local_prgs.output.prg,
    output:
        index=compare_dir / f"{{prg_name}}/{{prg_name}}.prg.k{K}.w{W}.idx",
        kmer_prgs=directory(compare_dir / "{prg_name}/kmer_prgs"),
    threads: 16
    resources:
        mem_mb=lambda wildcards, attempt: int(8 * GB) * attempt,
    params:
        K=K,
        W=W,
    log:
        rule_log_dir / "index_multi_sample_updated_prg/{prg_name}.log",
    container:
        containers["pandora"]
    shell:
        """
        pandora index -k {params.K} -w {params.W} -t {threads} {input.prg} > {log} 2>&1
        """


rule create_sample_index:
    output:
        sample_idx=nanopore_dir / "sample_idx.tsv",
    threads: 1
    resources:
        mem_mb=int(0.3 * GB),
    log:
        rule_log_dir / "create_sample_index.log",
    params:
        qc_dir=qc_dir,
        samplesheet=samplesheet,
    container:
        containers["conda"]
    conda:
        envs["create_sample_index"]
    script:
        scripts["create_sample_index"]


rule multi_sample_compare:
    input:
        prg=rules.combine_multi_sample_local_prgs.output.prg,
        idx=rules.index_multi_sample_updated_prg.output.index,
        sample_idx=rules.create_sample_index.output.sample_idx,
    output:
        gt_vcf=compare_dir / "{prg_name}/pandora/pandora_multisample_genotyped.vcf",
        consensus_vcf=(
            compare_dir / "{prg_name}/pandora/pandora_multisample_consensus.vcf"
        ),
        matrix=compare_dir / "{prg_name}/pandora/pandora_multisample.matrix",
    threads: 16
    resources:
        mem_mb=lambda wildcards, attempt: int(16 * GB) * attempt,
    container:
        containers["pandora"]
    params:
        outdir=lambda wildcards, output: Path(output.gt_vcf).parent,
        options=" ".join(
            [
                f"-k {K}",
                f"-w {W}",
                f"-e {config['pandora_e']}",
                f"-g {config['genome_size']}",
                "--genotype",
                f"-E {config['pandora_E']}",
            ]
        ),
    log:
        rule_log_dir / "multi_sample_compare/{prg_name}.log",
    shell:
        """
        pandora compare {params.options} -o {params.outdir} -t {threads} \
          {input.prg} {input.sample_idx} 2> {log}
        """
