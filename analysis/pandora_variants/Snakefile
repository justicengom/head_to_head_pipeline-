import os
from pathlib import Path
from typing import Dict, Union, List

import pandas as pd
from snakemake.utils import min_version

min_version("5.14.0")

GB = 1_024
PathLike = Union[str, Path, os.PathLike]


# ======================================================
# Config files
# ======================================================
configfile: "config.yaml"


# only load samples that passed QC and are not excluded
inclusion_expr = "failed_qc == 0 and excluded == 0"
samplesheet = pd.read_csv(config["samplesheet"]).query(inclusion_expr)
containers: Dict[str, PathLike] = config["containers"]
envs: Dict[str, PathLike] = config["envs"]
scripts: Dict[str, PathLike] = config["scripts"]
rule_log_dir = Path("logs/stderr").resolve()
H37RV = config["h37rv"]
data_dir = Path(config["data_dir"]).resolve()
build_prg_dir = Path(config["build_prg_dir"])
qc_dir = Path(config["qc_dir"])
filters = config["filters"]
discover = config["discover"]
report_dir = Path("report").resolve()
compass_vcf_dir = Path(config["compass_vcf_dir"]).resolve()
asm_dir = Path(config["asm_dir"]).resolve()
assemblies: Dict[str, str] = config["assemblies"]
nanopore_dir = Path("nanopore").resolve()
concordance_dir = Path("concordance").resolve()
consensus_dir = Path("consensus").resolve()
distance_dir = Path("distance").resolve()
truth_eval_dir = Path("truth_eval").resolve()
discover_dir = nanopore_dir / "discover"
genotype_dir = nanopore_dir / "genotype"
filter_dir = nanopore_dir / "filtered"
baseline_variant_dir = Path(config["baseline_variant_dir"]).resolve()
# ======================================================
# Global functions and variables
# ======================================================
K: int = config["pandora_k"]
W: int = config["pandora_w"]
SITES = samplesheet["site"]
SAMPLES = samplesheet["sample"]
VARIFIER_JSONS = set()
prg_names: List[str] = config["prg_names"]

output_files = set()
for idx, row in samplesheet.iterrows():
    site = row["site"]
    sample = row["sample"]

    for prg_name in prg_names:
        output_files.add(filter_dir / f"{prg_name}/{site}/{sample}.filtered.bcf")

        if row["pacbio"] == 1:
            pandora_truth_summary = (
                truth_eval_dir / f"{prg_name}/{sample}/summary_stats.json"
            )
            # compass_truth_summary = baseline_variant_dir / f"truth_eval/{sample}/compass/summary_stats.json"
            VARIFIER_JSONS.add(pandora_truth_summary)
# VARIFIER_JSONS.add(compass_truth_summary)

output_files.add(truth_eval_dir / "truth_all_eval.recall.png")
output_files.add(truth_eval_dir / "truth_all_eval.precision.png")


# ======================================================
# Sub Workflows
# ======================================================
subworkflow build_prg:
    workdir: build_prg_dir
    snakefile: build_prg_dir / "Snakefile"
    configfile: build_prg_dir / "config.yaml"


subworkflow qc:
    workdir: qc_dir
    snakefile: qc_dir / "Snakefile"
    configfile: qc_dir / "config.yaml"


# ======================================================
# Rules
# ======================================================
localrules:
    all,


rule all:
    input:
        output_files,


rule discover_denovo_variants:
    input:
        prg=build_prg("prgs/{prg_name}/{prg_name}.prg"),
        prg_index=build_prg(f"prgs/{{prg_name}}/{{prg_name}}.prg.k{K}.w{W}.idx"),
        reads=qc("subsampled/{site}/nanopore/{sample}/{sample}.subsampled.fastq.gz"),
    output:
        denovo_dir=directory(discover_dir / "{prg_name}/{site}/{sample}/denovo_paths"),
        consensus=discover_dir / "{prg_name}/{site}/{sample}/pandora.consensus.fq.gz",
    threads: 8
    resources:
        mem_mb=lambda wildcards, attempt: int(4 * GB) * attempt,
    container:
        containers["pandora"]
    log:
        rule_log_dir / "discover_denovo_variants/{prg_name}/{site}/{sample}.log",
    params:
        outdir=lambda wildcards, output: Path(output.denovo_dir).parent,
        prg=lambda wildcards, input: Path(input.prg).resolve(),
        reads=lambda wildcards, input: Path(input.reads).resolve(),
        options=" ".join(
            [
                f"-k {K}",
                f"-w {W}",
                f"-g {config['genome_size']}",
                "-v",
                f"--min-dbg-dp {discover['min_dbg_abundance']}",
                f"-d {discover['merge_dist']}",
                f"-L {discover['max_candidate_len']}",
            ]
        ),
    shell:
        """
        LOG=$(realpath {log})
        cd {params.outdir} || exit 1
        rm -rf ./*
        pandora discover {params.options} -t {threads} -o "$PWD" {params.prg} {params.reads} > "$LOG" 2>&1
        """


rule update_msas_for_single_sample:
    input:
        denovo_paths=rules.discover_denovo_variants.output.denovo_dir,
        msa_dir=build_prg("prgs/{prg_name}/multiple_sequence_alignments"),
    output:
        updated_msas=directory(
            discover_dir / "{prg_name}/{site}/{sample}/updated_msas"
        ),
    threads: 16
    resources:
        mem_mb=lambda wildcards, attempt: int(16 * GB) * attempt,
    container:
        containers["conda"]
    conda:
        envs["update_msas"]
    log:
        rule_log_dir / "update_msas_for_single_sample/{prg_name}/{site}/{sample}.log",
    params:
        script=scripts["update_msas"],
        options="",
    shell:
        """
        python {params.script} {params.options} -o {output.updated_msas} \
            -j {threads} -M {input.msa_dir} {input.denovo_paths} 2> {log}
        """


rule make_single_sample_local_prgs:
    input:
        msa_dir=rules.update_msas_for_single_sample.output.updated_msas,
    output:
        local_prg_dir=directory(
            discover_dir / "{prg_name}/{site}/{sample}/local_prgs"
        ),
    threads: 16
    resources:
        mem_mb=lambda wildcards, attempt: int(4 * GB) * attempt,
    singularity:
        containers["make_prg"]
    params:
        extras="--no-ignore --hidden --show-errors",
        extension="fa",
        pattern=".",
        script=scripts["make_prg"],
        nesting_lvl=config["nesting_level"],
        match_len=config["match_length"],
    log:
        rule_log_dir / "make_single_sample_local_prgs/{prg_name}/{site}/{sample}.log",
    shell:
        """
        mkdir -p {output.local_prg_dir} 2> {log}
        fd {params.extras} \
            --extension {params.extension} \
            --threads {threads} \
            --exec sh {params.script} '{{}}' \
                {output.local_prg_dir}/'{{/.}}' \
                {params.nesting_lvl} \
                {params.match_len} \
                {log} \; \
            {params.pattern} {input.msa_dir} 2>> {log}
        """


rule combine_single_sample_local_prgs:
    input:
        local_prg_dir=rules.make_single_sample_local_prgs.output.local_prg_dir,
    output:
        prg=discover_dir / "{prg_name}/{site}/{sample}/{prg_name}.{sample}.prg",
    threads: 1
    resources:
        mem_mb=int(0.5 * GB),
    params:
        extras="--no-ignore --hidden",
        extension="prg",
        pattern=".",
    container:
        containers["conda"]
    conda:
        envs["fd"]
    log:
        rule_log_dir / "combine_single_sample_local_prgs/{prg_name}/{site}/{sample}.log",
    shell:
        """
        fd {params.extras} \
            --extension {params.extension} \
            --exec-batch awk 1 \; \
            {params.pattern} {input.local_prg_dir} > {output.prg} 2> {log}
        """


rule index_single_sample_updated_prg:
    input:
        prg=rules.combine_single_sample_local_prgs.output.prg,
    output:
        index=(
            discover_dir
            / f"{{prg_name}}/{{site}}/{{sample}}/{{prg_name}}.{{sample}}.prg.k{K}.w{W}.idx"
        ),
        kmer_prgs=directory(discover_dir / "{prg_name}/{site}/{sample}/kmer_prgs"),
    threads: 16
    resources:
        mem_mb=lambda wildcards, attempt: int(8 * GB) * attempt,
    params:
        K=K,
        W=W,
    log:
        rule_log_dir / "index_single_sample_updated_prg/{prg_name}/{site}/{sample}.log",
    container:
        containers["pandora"]
    shell:
        """
        pandora index -k {params.K} -w {params.W} -t {threads} {input.prg} > {log} 2>&1
        """


rule single_sample_genotype:
    input:
        prg=rules.combine_single_sample_local_prgs.output.prg,
        prg_index=rules.index_single_sample_updated_prg.output.index,
        reads=rules.discover_denovo_variants.input.reads,
        vcf_refs=build_prg("prgs/reference_loci/loci_reference.fa"),
    output:
        vcf=genotype_dir / f"{{prg_name}}/{{site}}/{{sample}}/pandora_genotyped.vcf",
    threads: 8
    resources:
        mem_mb=lambda wildcards, attempt: int(4 * GB) * attempt,
    container:
        containers["pandora"]
    log:
        rule_log_dir / "single_sample_genotype/{prg_name}/{site}/{sample}.log",
    params:
        outdir=lambda wildcards, output: Path(output.vcf).parent,
        max_covg=1_000, # i.e. disable subsampling
        prg=lambda wildcards, input: Path(input.prg).resolve(),
        reads=lambda wildcards, input: Path(input.reads).resolve(),
        vcf_refs=lambda wildcards, input: Path(input.vcf_refs).resolve(),
        options=" ".join(
            [
                f"--genotype",
                f"-k {K}",
                f"-w {W}",
                f"-g {config['genome_size']}",
                "--kg",
                "--loci-vcf",
            ]
        ),
    shell:
        """
        LOG=$(realpath {log})
        cd {params.outdir} || exit 1
        rm -rf ./*
        pandora map {params.options} -t {threads} -o "$PWD" --vcf-refs {params.vcf_refs} \
            {params.prg} {params.reads}  > "$LOG" 2>&1
        """


rule normalise_single_sample_vcf:
    input:
        vcf=rules.single_sample_genotype.output.vcf,
        loci_info=build_prg("prgs/reference_loci/loci-info.csv"),
        ref=H37RV["genome"],
    output:
        vcf=genotype_dir / "{prg_name}/{site}/{sample}/{sample}.normalised.bcf",
    log:
        rule_log_dir / "normalise_single_sample_vcf_positions/{prg_name}/{site}/{sample}.log",
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: int(2 * GB) * attempt,
    params:
        options="-v",
        script=scripts["normalise_pos"],
        norm_opts="-c e -O b",
    container:
        containers["conda"]
    conda:
        envs["normalise_pos"]
    shell:
        """
        (sed 's/Number=A/Number=R/' {input.vcf} \
        | python {params.script} -l {input.loci_info} -r {input.ref} {params.options} \
        | bcftools sort \
        | bcftools norm {params.norm_opts} -f {input.ref} -o {output.vcf}) 2> {log}
        """


rule filter_single_sample_vcf:
    input:
        vcf=rules.normalise_single_sample_vcf.output.vcf,
    output:
        vcf=filter_dir / "{prg_name}/{site}/{sample}.filtered.bcf",
    threads: 1
    resources:
        mem_mb=int(0.5 * GB),
    params:
        options=" ".join(
            [
                "--verbose",
                "--overwrite",
                f"-d {filters['min_covg']}",
                f"-D {filters['max_covg']}",
                f"-s {filters['min_strand_bias']}",
                f"-g {filters['min_gt_conf']}",
                f"-G {filters['max_gaps']}",
            ]
        ),
        script=scripts["filter"],
    log:
        rule_log_dir / "filter_single_sample_vcf/{prg_name}/{site}/{sample}.log",
    container:
        containers["conda"]
    conda:
        envs["filter"]
    shell:
        """
        python {params.script} {params.options} \
            -i {input.vcf} \
            -o {output.vcf} 2> {log}
        """


def infer_assembly_path(wildcards):
    asm = assemblies[wildcards.sample]
    return f"{asm_dir}/{wildcards.sample}/{asm}/pacbio/decontam.assembly.{asm}.pacbio.fasta"


def infer_assembly_mask_path(wildcards):
    asm = assemblies[wildcards.sample]
    return f"{asm_dir}/{wildcards.sample}/{asm}/pacbio/assessment/{wildcards.sample}.{asm}.accuracy.pacbio.bed"


rule evaluate_all_variants_single_sample:
    input:
        truth_asm=infer_assembly_path,
        vcf_ref=H37RV["genome"],
        vcf_to_eval=filter_dir / "{prg_name}/madagascar/{sample}.filtered.bcf",
        ref_mask=H37RV["mask"],
        truth_mask=infer_assembly_mask_path,
    output:
        summary=report(
            truth_eval_dir / "{prg_name}/{sample}/summary_stats.json",
            category="Truth Evaluation",
            subcategory="Raw data",
            caption=report_dir / "varifier.rst",
        ),
    threads: 4
    resources:
        mem_mb=lambda wildcards, attempt: int(10 * GB) * attempt,
    params:
        options="--force",
        flank_length=100,
        outdir=lambda wildcards, output: Path(output.summary).parent,
    log:
        rule_log_dir / "evaluate_all_variants_single_sample/{prg_name}/{sample}.log",
    container:
        containers["conda"]
    conda:
        envs["varifier"]
    shell:
        """
        (bcftools view -O v {input.vcf_to_eval} \
        | varifier --debug vcf_eval {params.options} \
            --flank_length {params.flank_length} \
            --ref_mask {input.ref_mask} \
            --truth_mask {input.truth_mask} \
            {input.truth_asm} \
            {input.vcf_ref} \
            - \
            {params.outdir}) 2> {log}
        """


rule plot_evaluation_all_variants_single_sample:
    input:
        json_files=VARIFIER_JSONS,
    output:
        recall_plot=report(
            truth_eval_dir / "truth_all_eval.recall.png",
            category="Truth Evaluation",
            subcategory="Recall",
            caption=report_dir / "truth_all_eval.rst",
        ),
        precision_plot=report(
            truth_eval_dir / "truth_all_eval.precision.png",
            category="Truth Evaluation",
            subcategory="Precision",
            caption=report_dir / "truth_all_eval.rst",
        ),
    threads: 1
    resources:
        mem_mb=int(GB * 0.5),
    container:
        containers["conda"]
    conda:
        envs["plot_truth_eval"]
    params:
        recall_key="Recall_edit_dist",
        precision_key="Precision_edit_dist",
        dpi=300,
        figsize=(13, 8),
    script:
        scripts["plot_truth_eval"]
