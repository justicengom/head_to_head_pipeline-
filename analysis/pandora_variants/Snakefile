import os
from pathlib import Path
from typing import Dict, Union, List

import pandas as pd
from snakemake.utils import min_version

min_version("5.14.0")

GB = 1_024
PathLike = Union[str, Path, os.PathLike]


# ======================================================
# Config files
# ======================================================
configfile: "config.yaml"


# only load samples that passed QC and are not excluded
inclusion_expr = "failed_qc == 0 and excluded == 0"
samplesheet = pd.read_csv(config["samplesheet"]).query(inclusion_expr)
containers: Dict[str, PathLike] = config["containers"]
envs: Dict[str, PathLike] = config["envs"]
scripts: Dict[str, PathLike] = config["scripts"]
rule_log_dir = Path("logs/stderr").resolve()
H37RV = config["h37rv"]
data_dir = Path(config["data_dir"]).resolve()
build_prg_dir = Path(config["build_prg_dir"])
qc_dir = Path(config["qc_dir"])
filters = config["filters"]
report_dir = Path("report").resolve()
compass_vcf_dir = Path(config["compass_vcf_dir"]).resolve()
asm_dir = Path(config["asm_dir"]).resolve()
assemblies: Dict[str, str] = config["assemblies"]
nanopore_dir = Path("nanopore").resolve()
concordance_dir = Path("concordance").resolve()
consensus_dir = Path("consensus").resolve()
distance_dir = Path("distance").resolve()
truth_eval_dir = Path("truth_eval").resolve()
discover_dir = nanopore_dir / "discover"
genotype_dir = nanopore_dir / "genotype"
# ======================================================
# Global functions and variables
# ======================================================
K: int = config["pandora_k"]
W: int = config["pandora_w"]
GT_MODE: str = config["gt_mode"]
SITES = samplesheet["site"]
SAMPLES = samplesheet["sample"]
prg_names: List[str] = config["prg_names"]

output_files = set()
for idx, row in samplesheet.iterrows():
    site = row["site"]
    sample = row["sample"]

    for prg_name in prg_names:
        output_files.add(genotype_dir / f"{prg_name}/{site}/{sample}.normalised.bcf")


# ======================================================
# Sub Workflows
# ======================================================
subworkflow build_prg:
    workdir: build_prg_dir
    snakefile: build_prg_dir / "Snakefile"
    configfile: build_prg_dir / "config.yaml"


subworkflow qc:
    workdir: qc_dir
    snakefile: qc_dir / "Snakefile"
    configfile: qc_dir / "config.yaml"


# ======================================================
# Rules
# ======================================================
localrules:
    all,


rule all:
    input:
        output_files,


rule discover_denovo_variants:
    input:
        prg=build_prg("prgs/{prg_name}/{prg_name}.prg"),
        prg_index=build_prg(f"prgs/{{prg_name}}/{{prg_name}}.prg.k{K}.w{W}.idx"),
        reads=qc("subsampled/{site}/nanopore/{sample}/{sample}.subsampled.fastq.gz"),
        vcf_refs=build_prg("prgs/reference_loci/loci_reference.fa"),
    output:
        denovo_dir=directory(discover_dir / "{prg_name}/{site}/{sample}/denovo_paths"),
        consensus=discover_dir / "{prg_name}/{site}/{sample}/pandora.consensus.fq.gz",
    threads: 8
    resources:
        mem_mb=lambda wildcards, attempt: int(4 * GB) * attempt,
    container:
        containers["pandora"]
    log:
        rule_log_dir / "discover_denovo_variants/{prg_name}/{site}/{sample}.log",
    params:
        outdir=lambda wildcards, output: Path(output.denovo_dir).parent,
        max_covg=1_000, # i.e. disable subsampling
        prg=lambda wildcards, input: Path(input.prg).resolve(),
        reads=lambda wildcards, input: Path(input.reads).resolve(),
        vcf_refs=lambda wildcards, input: Path(input.vcf_refs).resolve(),
        options=" ".join(
            [
                "--discover",
                f"-k {K}",
                f"-w {W}",
                f"--genome_size {config['genome_size']}",
                "--log_level info",
            ]
        ),
    shell:
        """
        LOG=$(realpath {log})
        cd {params.outdir} || exit 1
        rm -rf ./*
        pandora map {params.options} -t {threads} -o "$PWD" -p {params.prg} \
            -r {params.reads} --vcf_refs {params.vcf_refs} > "$LOG" 2>&1
        """


rule update_msas_for_single_sample:
    input:
        denovo_paths=rules.discover_denovo_variants.output.denovo_dir,
        msa_dir=build_prg("prgs/{prg_name}/multiple_sequence_alignments"),
    output:
        updated_msas=directory(
            discover_dir / "{prg_name}/{site}/{sample}/updated_msas"
        ),
    threads: 16
    resources:
        mem_mb=lambda wildcards, attempt: int(16 * GB) * attempt,
    container:
        containers["conda"]
    conda:
        envs["update_msas"]
    log:
        rule_log_dir / "update_msas_for_single_sample/{prg_name}/{site}/{sample}.log",
    params:
        script=scripts["update_msas"],
        options="",
    shell:
        """
        python {params.script} {params.options} -o {output.updated_msas} \
            -j {threads} -M {input.msa_dir} {input.denovo_paths} 2> {log}
        """


rule make_single_sample_local_prgs:
    input:
        msa_dir=rules.update_msas_for_single_sample.output.updated_msas,
    output:
        local_prg_dir=directory(
            discover_dir / "{prg_name}/{site}/{sample}/local_prgs"
        ),
    threads: 16
    resources:
        mem_mb=lambda wildcards, attempt: int(4 * GB) * attempt,
    singularity:
        containers["make_prg"]
    params:
        extras="--no-ignore --hidden --show-errors",
        extension="fa",
        pattern=".",
        script=scripts["make_prg"],
        nesting_lvl=config["nesting_level"],
        match_len=config["match_length"],
    log:
        rule_log_dir / "make_single_sample_local_prgs/{prg_name}/{site}/{sample}.log",
    shell:
        """
        mkdir -p {output.local_prg_dir} 2> {log}
        fd {params.extras} \
            --extension {params.extension} \
            --threads {threads} \
            --exec sh {params.script} '{{}}' \
                {output.local_prg_dir}/'{{/.}}' \
                {params.nesting_lvl} \
                {params.match_len} \
                {log} \; \
            {params.pattern} {input.msa_dir} 2>> {log}
        """


rule combine_single_sample_local_prgs:
    input:
        local_prg_dir=rules.make_single_sample_local_prgs.output.local_prg_dir,
    output:
        prg=discover_dir / "{prg_name}/{site}/{sample}/{prg_name}.{sample}.prg",
    threads: 1
    resources:
        mem_mb=int(0.5 * GB),
    params:
        extras="--no-ignore --hidden",
        extension="prg",
        pattern=".",
    container:
        containers["conda"]
    conda:
        envs["fd"]
    log:
        rule_log_dir / "combine_single_sample_local_prgs/{prg_name}/{site}/{sample}.log",
    shell:
        """
        fd {params.extras} \
            --extension {params.extension} \
            --exec-batch awk 1 \; \
            {params.pattern} {input.local_prg_dir} > {output.prg} 2> {log}
        """


rule index_single_sample_updated_prg:
    input:
        prg=rules.combine_single_sample_local_prgs.output.prg,
    output:
        index=(
            discover_dir
            / f"{{prg_name}}/{{site}}/{{sample}}/{{prg_name}}.{{sample}}.prg.k{K}.w{W}.idx"
        ),
        kmer_prgs=directory(discover_dir / "{prg_name}/{site}/{sample}/kmer_prgs"),
    threads: 16
    resources:
        mem_mb=lambda wildcards, attempt: int(8 * GB) * attempt,
    params:
        K=K,
        W=W,
    log:
        rule_log_dir / "index_single_sample_updated_prg/{prg_name}/{site}/{sample}.log",
    container:
        containers["pandora"]
    shell:
        """
        pandora index -k {params.K} -w {params.W} -t {threads} {input.prg} > {log} 2>&1
        """


rule single_sample_genotype:
    input:
        prg=rules.combine_single_sample_local_prgs.output.prg,
        prg_index=rules.index_single_sample_updated_prg.output.index,
        reads=rules.discover_denovo_variants.input.reads,
        vcf_refs=rules.discover_denovo_variants.input.vcf_refs,
    output:
        vcf=(
            genotype_dir
            / f"{{prg_name}}/{{site}}/{{sample}}/pandora_genotyped_{GT_MODE}.vcf"
        ),
    threads: 8
    resources:
        mem_mb=lambda wildcards, attempt: int(4 * GB) * attempt,
    container:
        containers["pandora"]
    log:
        rule_log_dir / "single_sample_genotype/{prg_name}/{site}/{sample}.log",
    params:
        outdir=lambda wildcards, output: Path(output.vcf).parent,
        max_covg=1_000, # i.e. disable subsampling
        prg=lambda wildcards, input: Path(input.prg).resolve(),
        reads=lambda wildcards, input: Path(input.reads).resolve(),
        vcf_refs=lambda wildcards, input: Path(input.vcf_refs).resolve(),
        options=" ".join(
            [
                f"--genotype {GT_MODE}",
                f"-k {K}",
                f"-w {W}",
                f"--genome_size {config['genome_size']}",
                "--log_level info",
                "--output_kg",
                "--output_vcf",
                "--output_covgs",
            ]
        ),
    shell:
        """
        LOG=$(realpath {log})
        cd {params.outdir} || exit 1
        rm -rf ./*
        pandora map {params.options} -t {threads} -o "$PWD" -p {params.prg} \
            -r {params.reads} --vcf_refs {params.vcf_refs} > "$LOG" 2>&1
        """


rule normalise_single_sample_vcf:
    input:
        vcf=rules.single_sample_genotype.output.vcf,
        loci_info=build_prg("prgs/reference_loci/loci-info.csv"),
        ref=H37RV["genome"],
    output:
        vcf=genotype_dir / "{prg_name}/{site}/{sample}.normalised.bcf",
    log:
        rule_log_dir / "normalise_single_sample_vcf_positions/{prg_name}/{site}/{sample}.log",
    params:
        options="-v",
        script=scripts["normalise_pos"],
        norm_opts="-c e -O b",
    container:
        containers["conda"]
    conda:
        envs["normalise_pos"]
    shell:
        """
        (sed 's/Number=A/Number=R/' {input.vcf} \
        | python {params.script} -l {input.loci_info} -r {input.ref} {params.options} \
        | bcftools sort \
        | bcftools norm {params.norm_opts} -f {input.ref} -o {output.vcf}) 2> {log}
        """
