import os
from pathlib import Path
from typing import Dict, Union

import pandas as pd
from snakemake.utils import min_version

min_version("5.14.0")

GB = 1_024
PathLike = Union[str, Path, os.PathLike]


# ======================================================
# Config files
# ======================================================
configfile: "config.yaml"


samplesheet = pd.read_csv(config["samplesheet"])
containers: Dict[str, PathLike] = config["containers"]
envs: Dict[str, PathLike] = config["envs"]
scripts: Dict[str, PathLike] = config["scripts"]
rule_log_dir = Path("logs/stderr")
H37RV = config["h37rv"]
data_dir = Path(config["data_dir"])
filters = config["filters"]
report_dir = Path("report")
# plot_dir = report_dir / "plotting"
compass_vcf_dir = Path(config["compass_vcf_dir"])
nanopore_dir = Path("nanopore")
concordance_dir = Path("concordance")

# ======================================================
# Global functions and variables
# ======================================================
output_files = set()
samples = set()
for idx, row in samplesheet.iterrows():
    is_excluded = True if row["failed_qc"] == 1 else False
    if is_excluded:
        continue

    site = row["site"]
    sample = row["sample"]
    samples.add(sample)
    output_files.add(concordance_dir / f"{site}/{sample}.concordance.json")


# ======================================================
# Rules
# ======================================================
localrules:
    all,


report: report_dir / "workflow.rst"


rule all:
    input:
        output_files,


rule index_reference:
    input:
        H37RV["genome"],
    output:
        H37RV["genome"] + ".fai",
    log:
        rule_log_dir / "index_reference.log",
    wrapper:
        "0.63.0/bio/samtools/faidx"


rule map_nanopore:
    input:
        target=H37RV["genome"],
        query=data_dir / "{site}/nanopore/{sample}/{sample}.subsampled.fastq.gz",
    output:
        sam=nanopore_dir / "mapped/{site}/{sample}.sorted.sam",
    threads: 8
    resources:
        mem_mb=lambda wildcards, attempt: int(8 * GB) * attempt,
    container:
        containers["conda"]
    conda:
        envs["aln_tools"]
    params:
        minimap_extras=" ".join(["-a", "-L", "--sam-hit-only", "--secondary=no"]),
        minimap_preset="map-ont",
    log:
        rule_log_dir / "map_nanopore/{site}/{sample}.log",
    shell:
        """
        (minimap2 {params.minimap_extras} \
            -x {params.minimap_preset} \
            -t {threads} \
            {input.target} {input.query} | \
        samtools sort -@ {threads} -o {output.sam}) 2> {log}
        """


rule pileup_nanopore:
    input:
        index=rules.index_reference.output,
        ref=rules.index_reference.input[0],
        alignments=rules.map_nanopore.output.sam,
    output:
        pileup=nanopore_dir / "pileups/{site}/{sample}.pileup.bcf",
    threads: 2
    resources:
        mem_mb=lambda wildcards, attempt: {
            1: int(64 * GB),
            2: int(80 * GB),
            3: int(100 * GB),
        }[attempt],
    params:
        options="--ignore-overlaps -O b",
    log:
        rule_log_dir / "pileup_nanopore/{site}/{sample}.log",
    container:
        containers["conda"]
    wrapper:
        "0.64.0/bio/bcftools/mpileup"


rule call_snps_nanopore:
    input:
        pileup=rules.pileup_nanopore.output.pileup,
    output:
        calls=nanopore_dir / "snp_calls/{site}/{sample}.snps.bcf",
    threads: 2
    resources:
        mem_mb=lambda wildcards, attempt: int(GB) * attempt,
    params:
        caller="-m",
        options=" ".join(["--ploidy 1", "-O b", "--skip-variants indels"]),
    log:
        rule_log_dir / "call_snps_nanopore/{site}/{sample}.log",
    container:
        containers["conda"]
    wrapper:
        "0.64.0/bio/bcftools/call"


rule filter_nanopore_snps:
    input:
        vcf=rules.call_snps_nanopore.output.calls,
    output:
        vcf=nanopore_dir / "filtered_snps/{site}/{sample}.snps.filtered.bcf",
    threads: 1
    resources:
        mem_mb=int(GB),
    params:
        min_depth=filters["min_depth"],
        max_depth=filters["max_depth"],
        min_qual=filters["min_qual"],
        min_strand_bias=filters["min_strand_bias"],
        options="--hist --verbose --overwrite",
        script=scripts["filter"],
    log:
        rule_log_dir / "filter_nanopore_snps/{site}/{sample}.log",
    container:
        containers["conda"]
    conda:
        envs["filter"]
    shell:
        """
        python {params.script} {params.options} \
            -i {input.vcf} \
            -o {output.vcf} \
            -d {params.min_depth} \
            -D {params.max_depth} \
            -s {params.min_strand_bias} \
            -q {params.min_qual} 2> {log}
        """


rule calculate_concordance:
    input:
        truth=compass_vcf_dir / "{sample}.compass.vcf.gz",
        query=rules.filter_nanopore_snps.output.vcf,
        mask=H37RV["mask"],
    output:
        csv=concordance_dir / "{site}/{sample}.concordance.csv",
        json=concordance_dir / "{site}/{sample}.concordance.json",
    threads: 1
    resources:
        mem_mb=int(GB),
    params:
        options="--verbose --apply-filter",
        script=scripts["concordance"],
    log:
        rule_log_dir / "calculate_concordance/{site}/{sample}.log",
    container:
        containers["conda"]
    conda:
        envs["concordance"]
    shell:
        """
        python {params.script} {params.options} \
            -a {input.truth} \
            -b {input.query} \
            -m {input.mask} \
            -c {output.csv} \
            -j {output.json} 2> {log}
        """
