import os
from pathlib import Path
from typing import Dict, Union

import pandas as pd
from snakemake.utils import min_version

min_version("5.14.0")

GB = 1_024
PathLike = Union[str, Path, os.PathLike]


# ======================================================
# Config files
# ======================================================
configfile: "config.yaml"


# only load samples that passed QC and are not excluded
inclusion_expr = "failed_qc == 0 and excluded == 0"
samplesheet = pd.read_csv(config["samplesheet"]).query(inclusion_expr)
containers: Dict[str, PathLike] = config["containers"]
envs: Dict[str, PathLike] = config["envs"]
scripts: Dict[str, PathLike] = config["scripts"]
rule_log_dir = Path("logs/stderr").resolve()
H37RV = config["h37rv"]
data_dir = Path(config["data_dir"]).resolve()
filters = config["filters"]
report_dir = Path("report").resolve()
# plot_dir = report_dir / "plotting"
compass_vcf_dir = Path(config["compass_vcf_dir"]).resolve()
asm_dir = Path(config["asm_dir"]).resolve()
assemblies: Dict[str, str] = config["assemblies"]
nanopore_dir = Path("nanopore").resolve()
concordance_dir = Path("concordance").resolve()
consensus_dir = Path("consensus").resolve()
truth_eval_dir = Path("truth_eval").resolve()

# ======================================================
# Global functions and variables
# ======================================================
SITES = samplesheet["site"]
SAMPLES = samplesheet["sample"]
output_files = set()
output_files.add(concordance_dir / "alt_concordance.html")
FILTER_LOGS = set()
VARIFIER_JSONS = set()
for idx, row in samplesheet.iterrows():
    site = row["site"]
    sample = row["sample"]
    FILTER_LOGS.add(rule_log_dir / f"filter_nanopore_snps/{site}/{sample}.log")

    if row["pacbio"] == 1:
        compass_truth_summary = truth_eval_dir / f"{sample}/compass/summary_stats.json"
        bcftools_truth_summary = (
            truth_eval_dir / f"{sample}/bcftools/summary_stats.json"
        )
        VARIFIER_JSONS.add(compass_truth_summary)
        VARIFIER_JSONS.add(bcftools_truth_summary)

output_files.add(truth_eval_dir / "truth_snp_eval.recall.png")
output_files.add(consensus_dir / "bcftools/bcftools.consensus.fa")
output_files.add(consensus_dir / "compass/compass.consensus.fa")


# ======================================================
# Rules
# ======================================================
localrules:
    all,
    aggregate_consensus,


report: report_dir / "workflow.rst"


rule all:
    input:
        output_files,


rule index_reference:
    input:
        H37RV["genome"],
    output:
        H37RV["genome"] + ".fai",
    log:
        rule_log_dir / "index_reference.log",
    container:
        containers["conda"]
    wrapper:
        "0.63.0/bio/samtools/faidx"


rule map_nanopore:
    input:
        target=H37RV["genome"],
        query=data_dir / "{site}/nanopore/{sample}/{sample}.subsampled.fastq.gz",
    output:
        sam=temp(nanopore_dir / "mapped/{site}/{sample}.sorted.sam"),
    threads: 8
    resources:
        mem_mb=lambda wildcards, attempt: int(8 * GB) * attempt,
    container:
        containers["conda"]
    conda:
        envs["aln_tools"]
    params:
        minimap_extras=" ".join(["-a", "-L", "--sam-hit-only", "--secondary=no"]),
        minimap_preset="map-ont",
    log:
        rule_log_dir / "map_nanopore/{site}/{sample}.log",
    shell:
        """
        (minimap2 {params.minimap_extras} \
            -x {params.minimap_preset} \
            -t {threads} \
            {input.target} {input.query} | \
        samtools sort -@ {threads} -o {output.sam}) 2> {log}
        """


rule pileup_nanopore:
    input:
        index=rules.index_reference.output,
        ref=rules.index_reference.input[0],
        alignments=rules.map_nanopore.output.sam,
    output:
        pileup=nanopore_dir / "pileups/{site}/{sample}.pileup.bcf",
    threads: 2
    resources:
        mem_mb=lambda wildcards, attempt: {
            1: int(64 * GB),
            2: int(80 * GB),
            3: int(100 * GB),
        }[attempt],
    params:
        options="--ignore-overlaps -O b",
    log:
        rule_log_dir / "pileup_nanopore/{site}/{sample}.log",
    container:
        containers["conda"]
    wrapper:
        "0.64.0/bio/bcftools/mpileup"


rule call_snps_nanopore:
    input:
        pileup=rules.pileup_nanopore.output.pileup,
    output:
        calls=nanopore_dir / "snp_calls/{site}/{sample}.snps.bcf",
    threads: 2
    resources:
        mem_mb=lambda wildcards, attempt: int(GB) * attempt,
    params:
        caller="-m",
        options=" ".join(["--ploidy 1", "-O b", "--skip-variants indels"]),
    log:
        rule_log_dir / "call_snps_nanopore/{site}/{sample}.log",
    container:
        containers["conda"]
    wrapper:
        "0.64.0/bio/bcftools/call"


rule filter_nanopore_snps:
    input:
        vcf=rules.call_snps_nanopore.output.calls,
    output:
        vcf=nanopore_dir / "filtered_snps/{site}/{sample}.snps.filtered.bcf",
    threads: 1
    resources:
        mem_mb=int(GB),
    params:
        options=" ".join(
            [
                "--hist",
                "--verbose",
                "--overwrite",
                f"-d {filters['min_depth']}",
                f"-D {filters['max_depth']}",
                f"-q {filters['min_qual']}",
                f"-s {filters['min_strand_bias']}",
                f"-b {filters['min_bqb']}",
                f"-m {filters['min_mqb']}",
                f"-r {filters['min_rpb']}",
                f"-V {filters['min_vdb']}",
                f"-G {filters['max_sgb']}",
            ]
        ),
        script=scripts["filter"],
    log:
        rule_log_dir / "filter_nanopore_snps/{site}/{sample}.log",
    container:
        containers["conda"]
    conda:
        envs["filter"]
    shell:
        """
        python {params.script} {params.options} \
            -i {input.vcf} \
            -o {output.vcf} 2> {log}
        """


rule calculate_concordance:
    input:
        truth=compass_vcf_dir / "{sample}.compass.vcf.gz",
        query=rules.filter_nanopore_snps.output.vcf,
        mask=H37RV["mask"],
    output:
        csv=concordance_dir / "{site}/{sample}.concordance.csv",
        json=report(
            concordance_dir / "{site}/{sample}.concordance.json",
            category="Concordance",
            subcategory="Raw Data",
            caption=f"{report_dir}/calculate_concordance.rst",
        ),
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: int(2 * GB) * attempt,
    params:
        options="--verbose --apply-filter",
        script=scripts["concordance"],
    log:
        rule_log_dir / "calculate_concordance/{site}/{sample}.log",
    container:
        containers["conda"]
    conda:
        envs["concordance"]
    shell:
        """
        python {params.script} {params.options} \
            -a {input.truth} \
            -b {input.query} \
            -m {input.mask} \
            -c {output.csv} \
            -j {output.json} 2> {log}
        """


rule plot_concordance:
    input:
        jsons=expand(
            f"{concordance_dir}/{{site}}/{{sample}}.concordance.json",
            zip,
            site=SITES,
            sample=SAMPLES,
        ),
        filter_logs=FILTER_LOGS,
    output:
        alt_plot=report(
            concordance_dir / "alt_concordance.html",
            caption=f"{report_dir}/alt_concordance.rst",
            category="Concordance",
            subcategory="Plots",
        ),
        gw_plot=report(
            concordance_dir / "gw_concordance.html",
            caption=f"{report_dir}/gw_concordance.rst",
            category="Concordance",
            subcategory="Plots",
        ),
        depth_call_rate_plot=report(
            concordance_dir / "depth_call_rate.html",
            caption=f"{report_dir}/depth_call_rate.rst",
            category="Concordance",
            subcategory="Plots",
        ),
        depth_gw_call_rate_plot=report(
            concordance_dir / "depth_gw_call_rate.html",
            caption=f"{report_dir}/depth_gw_call_rate.rst",
            category="Concordance",
            subcategory="Plots",
        ),
        depth_concordance_plot=report(
            concordance_dir / "depth_concordance.html",
            caption=f"{report_dir}/depth_concordance.rst",
            category="Concordance",
            subcategory="Plots",
        ),
        depth_gw_concordance_plot=report(
            concordance_dir / "depth_gw_concordance.html",
            caption=f"{report_dir}/depth_gw_concordance.rst",
            category="Concordance",
            subcategory="Plots",
        ),
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: int(0.5 * GB) * attempt,
    params:
        colour_by="site",
        index="sample",
        log_scale=True,
    container:
        containers["conda"]
    conda:
        envs["plot_concordance"]
    script:
        scripts["plot_concordance"]


def infer_assembly_path(wildcards):
    asm = assemblies[wildcards.sample]
    return f"{asm_dir}/{wildcards.sample}/{asm}/pacbio/decontam.assembly.{asm}.pacbio.fasta"


def infer_assembly_mask_path(wildcards):
    asm = assemblies[wildcards.sample]
    return f"{asm_dir}/{wildcards.sample}/{asm}/pacbio/assessment/{wildcards.sample}.{asm}.accuracy.pacbio.bed"


rule evaluate_compass_snps_with_truth_assembly:
    input:
        truth_asm=infer_assembly_path,
        vcf_ref=H37RV["genome"],
        vcf_to_eval=compass_vcf_dir / "{sample}.compass.vcf.gz",
        ref_mask=H37RV["mask"],
        truth_mask=infer_assembly_mask_path,
    output:
        summary=report(
            truth_eval_dir / "{sample}/compass/summary_stats.json",
            category="Truth Evaluation",
            subcategory="Raw data",
            caption=report_dir / "varifier_compass.rst",
        ),
    threads: 4
    resources:
        mem_mb=lambda wildcards, attempt: int(22 * GB) * attempt,
    params:
        options="--force",
        flank_length=100,
        outdir=lambda wildcards, output: Path(output.summary).parent,
    log:
        rule_log_dir / "evaluate_compass_with_truth_assembly/{sample}.log",
    container:
        containers["conda"]
    conda:
        envs["varifier"]
    shell:
        """
        (bcftools view -O v {input.vcf_to_eval} \
        | varifier vcf_eval {params.options} \
            --flank_length {params.flank_length} \
            --ref_mask {input.ref_mask} \
            --truth_mask {input.truth_mask} \
            {input.truth_asm} \
            {input.vcf_ref} \
            - \
            {params.outdir}) 2> {log}
        """


rule evaluate_bcftools_snps_with_truth_assembly:
    input:
        truth_asm=infer_assembly_path,
        vcf_ref=H37RV["genome"],
        vcf_to_eval=(
            nanopore_dir / "filtered_snps/madagascar/{sample}.snps.filtered.bcf"
        ),
        ref_mask=H37RV["mask"],
        truth_mask=infer_assembly_mask_path,
    output:
        summary=report(
            truth_eval_dir / "{sample}/bcftools/summary_stats.json",
            category="Truth Evaluation",
            subcategory="Raw data",
            caption=report_dir / "varifier_bcftools.rst",
        ),
    threads: 4
    resources:
        mem_mb=lambda wildcards, attempt: int(22 * GB) * attempt,
    params:
        options="--force",
        flank_length=100,
        outdir=lambda wildcards, output: Path(output.summary).parent,
    log:
        rule_log_dir / "evaluate_bcftools_with_truth_assembly/{sample}.log",
    container:
        containers["conda"]
    conda:
        envs["varifier"]
    shell:
        """
        (bcftools view -O v {input.vcf_to_eval} \
        | varifier vcf_eval {params.options} \
            --flank_length {params.flank_length} \
            --ref_mask {input.ref_mask} \
            --truth_mask {input.truth_mask} \
            {input.truth_asm} \
            {input.vcf_ref} \
            - \
            {params.outdir}) 2> {log}
        """


rule plot_truth_snp_concordance:
    input:
        json_files=VARIFIER_JSONS,
    output:
        recall_plot=report(
            truth_eval_dir / "truth_snp_eval.recall.png",
            category="Truth Evaluation",
            subcategory="Recall",
            caption=report_dir / "truth_snp_eval.rst",
        ),
        precision_plot=report(
            truth_eval_dir / "truth_snp_eval.precision.png",
            category="Truth Evaluation",
            subcategory="Precision",
            caption=report_dir / "truth_snp_eval.rst",
        ),
    threads: 1
    resources:
        mem_mb=int(GB * 0.5),
    container:
        containers["conda"]
    conda:
        envs["plot_truth_eval"]
    params:
        recall_key="Recall",
        precision_key="Precision",
        dpi=300,
        figsize=(13, 8),
    script:
        scripts["plot_truth_eval"]


def infer_consensus_input(caller: str, sample: str, site: str) -> str:
    if caller == "compass":
        path = compass_vcf_dir / f"{sample}.compass.vcf.gz"
    elif caller == "bcftools":
        path = nanopore_dir / f"filtered_snps/{site}/{sample}.snps.filtered.bcf"
    else:
        raise NotImplemented(f"Caller {caller} is not known...")
    return str(path)


rule generate_consensus:
    input:
        mask=H37RV["mask"],
        ref_fasta=H37RV["genome"],
        vcf=lambda wildcards: infer_consensus_input(
            wildcards.caller, wildcards.sample, wildcards.site
        ),
    output:
        fasta=consensus_dir / "{caller}/{site}/{sample}.consensus.fa",
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: int(GB) * attempt,
    container:
        containers["conda"]
    conda:
        envs["consensus"]
    params:
        options=" ".join(
            ["--verbose", "--ignore all", "--sample-id {sample}", "--het-default none"]
        ),
        script=scripts["consensus"],
    log:
        rule_log_dir / "generate_consensus/{caller}/{site}/{sample}.log",
    shell:
        """
        python {params.script} {params.options} \
            -i {input.vcf} \
            -f {input.ref_fasta} \
            -m {input.mask} \
            -o {output.fasta} 2> {log}
        """


rule aggregate_consensus:
    input:
        fastas=expand(
            consensus_dir / "{{caller}}/{site}/{sample}.consensus.fa",
            zip,
            site=SITES,
            sample=SAMPLES,
        ),
    output:
        fasta=consensus_dir / "{caller}/{caller}.consensus.fa",
    threads: 1
    resources:
        mem_mb=int(GB),
    log:
        rule_log_dir / "aggregate_consensus/{caller}.log",
    shell:
        """
        awk 1 {input.fastas} > {output.fasta} 2> {log}
        """
