import os
from itertools import product
from pathlib import Path
from typing import Dict, Union

from snakemake.utils import min_version

min_version("5.14.0")

GB = 1_024
PathLike = Union[str, Path, os.PathLike]


# ======================================================
# Config files
# ======================================================
configfile: "config.yaml"


containers: Dict[str, PathLike] = config["containers"]
envs: Dict[str, PathLike] = config["envs"]
scripts: Dict[str, PathLike] = config["scripts"]
H37RV = config["h37rv"]
prg_dir = Path("prgs")
rare_lineages = set(config["rare_lineages"])
lineages = set(config["lineages"])
thresholds = set(config["thresholds"])
vcf_dir = Path("vcfs")

# ======================================================
# Global functions and variables
# ======================================================
output_files = set()
output_files.add(prg_dir / "reference_loci" / "loci-info.csv")
for lineage, threshold in product(lineages, thresholds):
    output_files.add(vcf_dir / f"subsampled-{threshold}.bcf.gz")


# ======================================================
# Rules
# ======================================================
rule all:
    input:
        output_files,


rule split_h37rv:
    input:
        genome=H37RV["genome"],
        features=H37RV["features"],
    output:
        info=prg_dir / "reference_loci" / "loci-info.csv",
    threads: 1
    resources:
        mem_mb=1 * GB,
    singularity:
        containers["conda"]
    conda:
        envs["gff_split"]
    params:
        script=scripts["gff_split"],
        outdir=lambda wildcards, output: Path(output.info).parent,
        types="gene",
        min_len=config["min_chunk_len"],
    shell:
        """
        python {params.script} --fasta {input.genome} \
            --gff {input.features} \
            --outdir {params.outdir} \
            --types {params.types} \
            --min-len {params.min_len} 
        """


rule assign_lineages:
    input:
        vcf=config["cryptic_vcf"],
        panel=config["lineage_panel"],
    output:
        assignments="resources/cryptic.lineages.csv",
    threads: 1
    resources:
        mem_mb=GB,
    singularity:
        containers["conda"]
    conda:
        envs["assign_lineages"]
    params:
        script=scripts["assign_lineages"],
        default_lineage=config["default_lineage"], # the name given to samples with no hits in the panel
        max_het=1,
        max_alt_lineages=1,
        ref_lineage_position=config["ref_lineage_position"],
        extras="--verbose",
    shell:
        """
        python {params.script} --input {input.vcf} \
            --panel {input.panel} \
            --output {output.assignments} \
            --default-lineage {params.default_lineage} \
            --max-het {params.max_het} \
            --ref-lineage-position {params.ref_lineage_position} \
            --max-alt-lineages {params.max_alt_lineages} {params.extras}
        """


rule create_samples_files:
    input:
        assignments=rules.assign_lineages.output.assignments,
    output:
        samples_file="resources/sample-list.L{lineage}.txt",
    threads: 1
    resources:
        mem_mb=int(0.2 * GB),
    run:
        samples = []
        with open(output.samples_file, "w") as outstream, open(input.assignments) as instream:
            for row in map(str.rstrip, instream):
                fields = row.split(",")
                sample = fields[0]
                lin = fields[1]
                if (
                    wildcards.lineage == "rare" and lin.lower() in rare_lineages
                ) or lin == wildcards.lineage:
                    print(sample, file=outstream)



rule split_into_lineage_vcfs:
    input:
        vcf=config["cryptic_vcf"],
        samples_file=rules.create_samples_files.output.samples_file,
    output:
        vcf=vcf_dir / "lineage" / "cryptic.L{lineage}.bcf.gz",
    threads: 4
    resources:
        mem_mb=GB,
    singularity:
        containers["bcftools"]
    params:
        output_type="b", # compressed BCF
        extras=" ".join(["--trim-alt-alleles", "--exclude-uncalled"]),
    shell:
        """
        bcftools view --threads {threads} \
            --samples-file {input.samples_file} \
            --output-type {params.output_type} \
            -o {output.vcf} \
            {params.extras} \
            {input.vcf}
        """


rule subsample_samples_files:
    input:
        samples_file=rules.create_samples_files.output.samples_file,
    output:
        samples_file="resources/sample-list.subsampled-{threshold}.L{lineage}.txt",
    threads: 1
    resources:
        mem_mb=int(0.3 * GB),
    params:
        seed=88,
    run:
        import random
        from pathlib import Path

        random.seed(params.seed)
        samples = list(filter(None, Path(input.samples_file).read_text().splitlines()))
        k = min(int(wildcards.threshold), len(samples))
        selections = random.sample(samples, k=k)
        content = "\n".join(selections)
        Path(output.samples_file).write_text(content)



rule subsample_vcfs:
    input:
        vcf=rules.split_into_lineage_vcfs.output.vcf,
        samples_file=rules.subsample_samples_files.output.samples_file,
    output:
        vcf=vcf_dir / "lineage" / "cryptic.subsampled-{threshold}.L{lineage}.bcf.gz",
    threads: 4
    resources:
        mem_mb=GB,
    singularity:
        containers["bcftools"]
    params:
        output_type="b", # compressed BCF
        extras=" ".join(["--trim-alt-alleles", "--exclude-uncalled"]),
    shell:
        """
        bcftools view --threads {threads} \
            --samples-file {input.samples_file} \
            --output-type {params.output_type} \
            -o {output.vcf} \
            {params.extras} \
            {input.vcf}
        """


rule index_vcfs:
    input:
        vcf=rules.subsample_vcfs.output.vcf,
    output:
        index=vcf_dir / "lineage" / "cryptic.subsampled-{threshold}.L{lineage}.bcf.gz.csi",
    threads: 4
    resources:
        mem_mb=GB,
    singularity:
        containers["bcftools"]
    params:
        extras=" ".join(["--csi", "--force"]),
    shell:
        """
        bcftools index --threads {threads} \
            {params.extras} \
            {input.vcf}
        """


rule merge_vcfs:
    input:
        cryptic_vcfs=expand(
            vcf_dir / "lineage" / "cryptic.subsampled-{{threshold}}.L{lineage}.bcf.gz",
            lineage=lineages,
        ),
        cryptic_indexes=expand(
            vcf_dir / "lineage" / "cryptic.subsampled-{{threshold}}.L{lineage}.bcf.gz.csi",
            lineage=lineages,
        ),
        comas_vcf=config["comas_vcf"],
    output:
        vcf=vcf_dir / "subsampled-{threshold}.bcf.gz",
    threads: 4
    resources:
        mem_mb=4 * GB,
    singularity:
        containers["bcftools"]
    params:
        output_type="b", # compressed BCF
        extras="",
    shell:
        """
        bcftools merge --threads {threads} \
            --output-type {params.output_type} \
            -o {output.vcf} \
            {params.extras} \
            {input.cryptic_vcfs} {input.comas_vcf}
        """
