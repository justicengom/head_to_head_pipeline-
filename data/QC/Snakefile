import os
from itertools import product
from pathlib import Path
from typing import Dict, Union

from snakemake.utils import min_version
import pandas as pd

min_version("5.14.0")

GB = 1_024
PathLike = Union[str, Path, os.PathLike]


# ======================================================
# Config files
# ======================================================
configfile: "config.yaml"


samplesheet = pd.read_csv(config["samplesheet"])
containers: Dict[str, PathLike] = config["containers"]
envs: Dict[str, PathLike] = config["envs"]
scripts: Dict[str, PathLike] = config["scripts"]
rule_log_dir = Path("logs/stderr")
decontam_db = Path("decontam_db")
data_dir = Path(config["data_dir"])
report_dir = Path("report")
plot_dir = report_dir / "plotting"
filtered_dir = Path("filtered")

# ======================================================
# Global functions and variables
# ======================================================
MM2_PRESET = "map-ont"
BWA_EXTNS = [".amb", ".ann", ".bwt", ".pac", ".sa"]
technologies = ["illumina", "nanopore"]

output_files = set()
for idx, row in samplesheet.iterrows():
    is_excluded = True if row["excluded"] == 1 else False
    if is_excluded:
        continue

    site = row["site"]
    sample = row["sample"]
    for tech in technologies:
        output_files.add(plot_dir / "krona" / f"{site}" / f"{sample}.{tech}.krona.html")


# ======================================================
# Rules
# ======================================================
localrules:
    all,


report: report_dir / "workflow.rst"


rule all:
    input:
        output_files,


rule build_decontamination_db:
    output:
        fasta=decontam_db / "remove_contam.fa.gz",
        metadata=decontam_db / "remove_contam.tsv",
    threads: 1
    resources:
        mem_mb=GB,
    params:
        script=scripts["download_decontam"],
        outdir=lambda wildcards, output: Path(output.fasta).parent,
    singularity:
        containers["conda"]
    conda:
        envs["decontam_db"]
    log:
        rule_log_dir / "build_decontamination_db.log",
    shell:
        """
        perl {params.script} {params.outdir} &> {log}
        """


rule index_decontam_db:
    input:
        fasta=rules.build_decontamination_db.output.fasta,
    output:
        bwa_index=multiext(str(decontam_db / "remove_contam.fa.gz"), *BWA_EXTNS),
        mm2_index=decontam_db / "remove_contam.fa.gz.map-ont.mmi",
    threads: 4
    resources:
        mem_mb=lambda wildcards, attempt: attempt * int(32 * GB),
    singularity:
        containers["conda"]
    conda:
        envs["aln_tools"]
    params:
        preset=MM2_PRESET,
        extras="-I 12G",
    log:
        rule_log_dir / "index_decontam_db.log",
    shell:
        """
        bwa index {input.fasta} 2> {log}
        minimap2 {params.extras} \
            -x {params.preset} \
            -t {threads} \
            -d {output.mm2_index} \
            {input.fasta} 2>> {log}
        """


rule map_illumina_to_decontam_db:
    input:
        index=rules.index_decontam_db.output.bwa_index,
        ref=rules.build_decontamination_db.output.fasta,
        r1=data_dir / "{site}" / "illumina" / "{sample}" / "{sample}.R1.fastq.gz",
        r2=data_dir / "{site}" / "illumina" / "{sample}" / "{sample}.R2.fastq.gz",
    output:
        bam="mapped/{site}/{sample}.illumina.sorted.bam",
        index="mapped/{site}/{sample}.illumina.sorted.bam.bai",
    threads: 8
    resources:
        mem_mb=lambda wildcards, attempt: attempt * int(12 * GB),
    params:
        map_extras="-M",
    log:
        rule_log_dir / "map_illumina_to_decontam_db" / "{site}" / "{sample}.log",
    shell:
        """
        (bwa mem {params.map_extras} -t {threads} {input.ref} {input.r1} {input.r2} | \
            samtools sort -@ {threads} -o {output.bam}) 2> {log}
        samtools index -@ {threads} {output.bam} &>> {log}
        """


rule map_nanopore_to_decontam_db:
    input:
        index=rules.index_decontam_db.output.mm2_index,
        query=data_dir / "{site}" / "nanopore" / "{sample}" / "{sample}.nanopore.fastq.gz",
    output:
        bam="mapped/{site}/{sample}.nanopore.sorted.bam",
        index="mapped/{site}/{sample}.nanopore.sorted.bam.bai",
    threads: 8
    resources:
        mem_mb=lambda wildcards, attempt: attempt * int(16 * GB),
    params:
        map_extras="-aL2",
        preset=MM2_PRESET,
    log:
        rule_log_dir / "map_nanopore_to_decontam_db" / "{site}" / "{sample}.log",
    shell:
        """
        (minimap2 {params.map_extras} -x {params.preset} -t {threads} {input.index} {input.query} | \
            samtools sort -@ {threads} -o {output.bam}) 2> {log}
        samtools index -@ {threads} {output.bam} &>> {log}
        """


rule filter_contamination_illumina:
    input:
        bam=rules.map_illumina_to_decontam_db.output.bam,
        metadata = rules.build_decontamination_db.output.metadata,
        r1=data_dir / "{site}" / "illumina" / "{sample}" / "{sample}.R1.fastq.gz",
        r2=data_dir / "{site}" / "illumina" / "{sample}" / "{sample}.R2.fastq.gz",
    output:
        r1 = filtered_dir / "{site}" / "illumina" / "{sample}" / "{sample}.filtered.R1.fastq.gz",
        r2 = filtered_dir / "{site}" / "illumina" / "{sample}" / "{sample}.filtered.R2.fastq.gz",
    threads: 1
    resources:
        mem_mb = GB
    singularity:
        containers["conda"]
    conda:
        envs["filter"]
    params:
        script=scripts["filter"]
    log:
        rule_log_dir / "filter_contamination_illumina" / "{site}" / "{sample}.log",
    shell:
        """
        python {params.script} 2> {log}
        """

rule generate_krona_input:
    input:
        bam="mapped/{site}/{sample}.{tech}.sorted.bam",
        metadata=rules.build_decontamination_db.output.metadata,
    output:
        krona_input=plot_dir / "krona" / "{site}" / "{sample}.{tech}.krona.tsv",
    threads: 1
    resources:
        mem_mb=int(0.4 * GB),
    singularity:
        containers["conda"]
    conda:
        envs["generate_krona_input"]
    params:
        script=scripts["generate_krona_input"],
        extras="--ignore-secondary",
    log:
        rule_log_dir / "generate_krona_input" / "{site}" / "{sample}.{tech}.log",
    shell:
        """
        python {params.script} {params.extras} \
            -i {input.bam} -m {input.metadata} -o {output.krona_input} 2> {log}
        """


rule plot_sample_composition:
    input:
        tsv=rules.generate_krona_input.output.krona_input,
    output:
        chart=report(
            plot_dir / "krona" / "{site}" / "{sample}.{tech}.krona.html",
            category="Krona",
            caption=report_dir / "krona.rst",
        ),
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * GB,
    singularity:
        containers["krona"]
    log:
        rule_log_dir / "plot_sample_composition" / "{site}" / "{sample}.{tech}.log",
    shell:
        """
        ktImportText {input.tsv} -o {output.chart} &> {log}
        """


# assign lineages for samples
# subsample to max. coverage
#
